library(shiny)
runApp("~/GitHub/xrf-app")
flores <- read.csv(file="~/Google Drive/Liang Bua XRF/Liang Bua/Combined-Net Photons.csv")#
flores.stat <- read.csv(file="~/Google Drive/Liang Bua XRF/Liang Bua/Combined-Net Photons Stat.csv")#
flores.no.mix <- read.csv(file="~/Google Drive/Liang Bua XRF/Liang Bua/Combined-Net Photons XXI.csv")#
flores.no.mix.stat <- read.csv(file="~/Google Drive/Liang Bua XRF/Liang Bua/Combined-Net Photons XXI Stat.csv")
lm_eqn = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(C)[i] == a + b %.% italic(I)[i]*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}#
#
lm_eqn_poly = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    c = format(abs(coef(m)[3]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(C)[i] == a + c %.% italic(I)[i]^2 + b %.% italic(I)[i]*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}
####All#
U <- flores$U.L1#
Y <- flores $Y.K12#
Nd <- flores $Nd.L12#
spit <- flores $Spit
quartz()#
U.plot <- qplot(Spit, U.L1, data=flores, xlab = "Spit", ylab = "Uranium Net Photons", colour = Unit, shape= Unit) + theme_bw() + stat_smooth(method="lm")#
U.plot
quartz()#
Y.plot <- qplot(Spit, Y.K12, data=flores, xlab = "Spit", ylab = "Yttrium Net Photons", colour = Unit, shape= Unit) + theme_bw() + stat_smooth(method="lm")#
Y.plot
###Iron-Titanium Plot#
quartz()#
fe.ti <- qplot(Fe.K12, Ti.K12, data=flores.no.mix, xlab = "Iron Net Photons", ylab = "Titanium Net Photons" ) + #
theme_bw() + #
stat_smooth(method="glm", formula = y~poly(x, 3))#
fe.ti
#####Comp Plot#
quartz()#
this <- qplot(Split, I.K12, data = flores, xlab = "Split", ylab = "% Element Relative Photons") + #
geom_point(aes(Split, I.K12, colour = "I")) + #
geom_point(aes(Split, La.L1, colour = "La")) + #
geom_point(aes(Split, Nd.L1, colour = "Nd")) + #
geom_point(aes(Split, Y.K12, colour = "Y")) + #
geom_point(aes(Split, Yb.L1, colour = "Yb")) + #
geom_point(aes(Split, U.L1, colour = "U")) + #
geom_line(aes(Split, I.K12, colour = "I")) + #
geom_line(aes(Split, La.L1, colour = "La")) + #
geom_line(aes(Split, Nd.L1, colour = "Nd")) + #
geom_line(aes(Split, Y.K12, colour = "Y")) + #
geom_line(aes(Split, Yb.L1, colour = "Yb")) + #
geom_line(aes(Split, U.L1, colour = "U")) + #
 scale_colour_manual("", #
                      breaks = c("I", "La", "Nd", "Y", "Yb", "U"), #
                      values = c("brown", "green", "purple", "blue", "red", "orange", "yellow" )) +#
theme_bw()#
this
#####Comp Plot#
quartz()#
this <- qplot(Spit, I.K12, data = flores, xlab = "Split", ylab = "% Element Relative Photons") +#
geom_point(aes(Spit, I.K12, colour = "I")) +#
geom_point(aes(Spit, La.L1, colour = "La")) +#
geom_point(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_point(aes(Spit, Y.K12, colour = "Y")) +#
geom_point(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_point(aes(Spit, U.L1, colour = "U")) +#
geom_line(aes(Spit, I.K12, colour = "I")) +#
geom_line(aes(Spit, La.L1, colour = "La")) +#
geom_line(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_line(aes(Spit, Y.K12, colour = "Y")) +#
geom_line(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_line(aes(Spit, U.L1, colour = "U")) +#
 scale_colour_manual("", #
                      breaks = c("I", "La", "Nd", "Y", "Yb", "U"), #
                      values = c("brown", "green", "purple", "blue", "red", "orange", "yellow" )) +#
theme_bw()#
this
#####Comp Plot#
quartz()#
this <- qplot(Spit, I.K12, data = flores, xlab = "Split", ylab = "% Element Relative Photons") +#
geom_point(aes(Spit, I.K12, colour = "I")) +#
#geom_point(aes(Spit, La.L1, colour = "La")) +#
geom_point(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_point(aes(Spit, Y.K12, colour = "Y")) +#
geom_point(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_point(aes(Spit, U.L1, colour = "U")) +#
geom_line(aes(Spit, I.K12, colour = "I")) +#
geom_line(aes(Spit, La.L1, colour = "La")) +#
geom_line(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_line(aes(Spit, Y.K12, colour = "Y")) +#
geom_line(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_line(aes(Spit, U.L1, colour = "U")) +#
 scale_colour_manual("", #
                      breaks = c("I", "La", "Nd", "Y", "Yb", "U"), #
                      values = c("brown", "green", "purple", "blue", "red", "orange", "yellow" )) +#
theme_bw()#
this
#####Comp Plot#
quartz()#
this <- qplot(Spit, I.K12, data = flores, xlab = "Split", ylab = "% Element Relative Photons") +#
geom_point(aes(Spit, I.K12, colour = "I")) +#
#geom_point(aes(Spit, La.L1, colour = "La")) +#
geom_point(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_point(aes(Spit, Y.K12, colour = "Y")) +#
#geom_point(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_point(aes(Spit, U.L1, colour = "U")) +#
geom_line(aes(Spit, I.K12, colour = "I")) +#
geom_line(aes(Spit, La.L1, colour = "La")) +#
geom_line(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_line(aes(Spit, Y.K12, colour = "Y")) +#
geom_line(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_line(aes(Spit, U.L1, colour = "U")) +#
 scale_colour_manual("", #
                      breaks = c("I", "La", "Nd", "Y", "Yb", "U"), #
                      values = c("brown", "green", "purple", "blue", "red", "orange", "yellow" )) +#
theme_bw()#
this
#####Comp Plot#
quartz()#
this <- qplot(Spit, I.K12, data = flores, xlab = "Split", ylab = "% Element Relative Photons") +#
geom_point(aes(Spit, I.K12, colour = "I")) +#
#geom_point(aes(Spit, La.L1, colour = "La")) +#
geom_point(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_point(aes(Spit, Y.K12, colour = "Y")) +#
#geom_point(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_point(aes(Spit, U.L1, colour = "U")) +#
geom_line(aes(Spit, I.K12, colour = "I")) +#
#geom_line(aes(Spit, La.L1, colour = "La")) +#
geom_line(aes(Spit, Nd.L1, colour = "Nd")) +#
geom_line(aes(Spit, Y.K12, colour = "Y")) +#
#geom_line(aes(Spit, Yb.L1, colour = "Yb")) +#
geom_line(aes(Spit, U.L1, colour = "U")) +#
 scale_colour_manual("", #
                      breaks = c("I", "La", "Nd", "Y", "Yb", "U"), #
                      values = c("brown", "green", "purple", "blue", "red", "orange", "yellow" )) +#
theme_bw()#
this
quartz()#
Y.plot <- qplot(Spit, Y.K12, data=flores, xlab = "Spit", ylab = "Yttrium Net Photons") + theme_bw() + stat_smooth(method="lm", formula=y~x^2)#
Y.plot
quartz()#
U.plot <- qplot(Spit, U.L1, data=flores, xlab = "Spit", ylab = "Uranium Net Photons") + theme_bw() + stat_smooth(method="lm", formula=y~x^2)#
U.plot
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, xlab = "Spit", ylab = "Uranium Net Photons") + theme_bw() + stat_smooth(method="lm", formula=y~x^2)#
U.plot
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") + theme_bw() + stat_smooth(method="glm", formula=y~x^2)#
U.plot
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") + theme_bw() + stat_smooth(method="glm", formula=y~x^2+x)#
U.plot
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") + theme_bw() + stat_smooth(method="glm", formula=y~poly(x, 2))#
U.plot
?stat_smooth
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") +#
theme_bw() +#
stat_smooth(method="glm", formula=y~poly(x, 2)) +#
annotate("text", label=lm_eqn_poly(lm(Spit~U.K12/300, flores)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
U.plot
quartz()#
U.plot <- qplot(U.L1, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") +#
theme_bw() +#
stat_smooth(method="glm", formula=y~poly(x, 2)) +#
annotate("text", label=lm_eqn_poly(lm(Spit~U.L1/300, flores)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
U.plot
quartz()#
U.plot <- qplot(U.L1/300, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") +#
theme_bw() +#
stat_smooth(method="lm", formula=y~poly(x, 2)) +#
annotate("text", label=lm_eqn_poly(lm(Spit~U.L1/300, flores)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
U.plot
U.plot <- qplot(U.L1/300, Spit, data=flores, ylab = "Spit", xlab = "Uranium Net Photons") +#
theme_bw() +#
stat_smooth(method="lm", formula=y~poly(x, 2))
U.plot
?lm
runApp("~/GitHub/xrf-app")
traceback()
runApp("~/GitHub/xrf-app")
moshe <- read.csv(file="~/Desktop/Moshe/Second/Points-Table 1.csv")
library(ggplot2)#
lm_eqn = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(C)[i] == a + b %.% italic(I)[i]*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}#
#
lm_eqn_val = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}#
#
#moshe <- read.csv(file="~/Desktop/Moshe/Moshe/Points-Table 1.csv")#
moshe <- read.csv(file="~/Desktop/Moshe/Second/Points-Table 1.csv")
layer.plot.s <- ggplot(moshe, aes(Second, S.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("S ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(S.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.s
layer.plot.cl <- ggplot(moshe, aes(Second, Cl.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Cl ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Cl.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.cl
layer.plot.k <- ggplot(moshe, aes(Second, K.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("K ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(K.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.k
layer.plot.ca <- ggplot(moshe, aes(Second, Ca.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Ca ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Ca.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.ca
layer.plot.cu <- ggplot(moshe, aes(Second, Cu.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Cu ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Cu.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.cu
moshe <- read.csv(file="~/Desktop/Moshe/Second/Points-500.csv")
moshe <- read.csv(file="~/Desktop/Moshe/Second/500-Table 1.csv")
layer.plot.cu <- ggplot(moshe, aes(Second, Cu.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Cu ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Cu.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.cu
layer.plot.s <- ggplot(moshe, aes(Second, S.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("S ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(S.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.s
layer.plot.k <- ggplot(moshe, aes(Second, K.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("K ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(K.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.k
layer.plot.ca <- ggplot(moshe, aes(Second, Ca.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Ca ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Ca.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.ca
moshe <- read.csv(file="~/Desktop/Moshe/Second/2500-Table 1.csv")
layer.plot.cu <- ggplot(moshe, aes(Second, Cu.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Cu ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Cu.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.cu
layer.plot.s <- ggplot(moshe, aes(Second, S.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("S ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(S.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.s
layer.plot.k <- ggplot(moshe, aes(Second, K.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("K ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(K.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.k
layer.plot.ca <- ggplot(moshe, aes(Second, Ca.K12/60)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_y_continuous("Ca ncps") +#
scale_x_continuous("Value", limits=c(0, 100)) +#
annotate("text", label=lm_eqn_val(lm(Ca.K12/60~Second, moshe)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_light()#
layer.plot.ca
library(ggplot2)
#Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
#packrat::init("~/Dropbox/4.2 ky event/Data Analysis/R Code/For Distribution/Neolithic")#
#
#Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###Load Packages#
library(TTR)#
library(ggplot2)#
library(gridExtra)#
library(scales)#
library(gtable)#
library(wq)#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape)#
library(sp)#
library(raster)#
library(rgdal)#
library(rgeos)#
library(maptools)#
library(sp)#
library(spatialEco)#
#
###Load Packages#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape2)#
library(pbapply)#
library(xlsx)#
library(data.table)#
library(dplyr)#
library(akima)#
library(ggmap)#
library(ggthemes)#
#
###Download Packages (if needed) at http://www.bleedrake.com/Neolithic/Neolithic.zip#
#
###Load Data#
neolithic.bio <- read.csv(file="http://www.bleedrake.com/Neolithic/neolithic.csv")#
all.data <- read.csv(file="~/Dropbox/4.2 ky event/Radiocarbon Final/All Iberia/Just Dates-1-Table 1.csv")#
#
###Load Calibration Curves#
intcal.13 <- read.csv(file="http://www.bleedrake.com/Neolithic/intcal13.csv")#
#####Collapse Dates#
collapse.the.dates.begin <- function(sites, biogeo, general, dates, sigma) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, biogeo, general, dates, sigma)#
    colnames(df) <- c("Site", "Biogeo_Uni", "St_Area_NE", "CYrBPunc", "Sigma")#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Biogeo_Uni))#
    df <- arrange(df, desc(St_Area_NE))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),4]-df[2:nrow(df), 4]))/((sqrt(df[2:nrow(df), 5]^2 + df[1:(nrow(df)-1),5]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),6], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(sites))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
#####Collapse Dates#
collapse.the.dates.new <- function(sites, region, context, dates, sigma, lat, long, datemin, datemax) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, region, context, lat, long, as.numeric(dates), as.numeric(sigma))#
    colnames(df) <- c("Site", "Region", "Context", "Lat", "Long", "CYrBPunc", "Sigma")#
    df <- subset(df, df$CYrBPunc < datemax & df$CYrBPunc > datemin)#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Region))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),6]-df[2:nrow(df), 6]))/((sqrt(df[2:nrow(df), 7]^2 + df[1:(nrow(df)-1),7]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),8], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(df$Site))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
neolithic.bio <- collapse.the.dates.begin(sites=neolithic.bio$Site, biogeo=neolithic.bio$Biogeo_Uni, general=neolithic.bio$St_Area_NE, dates=neolithic.bio$CYrBPunc, sigma=neolithic.bio$Sigma)#
#####Intersect 14C dates by region#
antonio.regions <- readOGR("/Users/lee/Dropbox/4.2 ky event/jwp paper/Event42_areasIberia", "Event42_areasIberia")#
antonio.p1 <- as(antonio.regions, "SpatialPolygons")#
antonio.p1@data$id = rownames(antonio.p1@data)#
#
small.frame <- data.frame(all.data$Region, all.data$Site, all.data$Site.Type, all.data$Site.Type.Simple, all.data$Context..phase..etc.., all.data$Lat.in.Dec, all.data$Long.in.Dec, all.data$Sample.Lab.Number, all.data$X14C.Yr.BP.uncal, all.data$Sigma)#
colnames(small.frame) <- c("Region", "Site", "Details", "Type", "Context", "Latitude", "Longitude", "LabNumber", "Date", "Sigma")#
small.frame <- small.frame[!(is.na(small.frame$Latitude) | small.frame$Latitude==""), ]#
small.frame <- small.frame[!(is.na(small.frame$Longitude) | small.frame$Longitude==""), ]#
small.frame$Region <- sub("^$", "0", small.frame$Region)#
small.frame$Site <- sub("^$", "0", small.frame$Site)#
small.frame$Type <- sub("^$", "0", small.frame$Type)#
small.frame$Context <- sub("^$", "0", small.frame$Context)#
small.frame$LabNumber <- sub("^$", "0", small.frame$LabNumber)#
small.frame$Date <- sub("^$", "0", small.frame$Date)#
small.frame$Sigma <- sub("^$", "0", small.frame$Sigma)#
iberia.points <- data.frame(small.frame)#
#
coordinates(iberia.points) = ~Longitude+Latitude#
proj4string(iberia.points) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0")#
#
iberia.points <- spTransform(iberia.points, CRS("+proj=utm +zone=30 +ellps=GRS80 +units=m +no_defs"))#
#
overlap <- over(iberia.points, antonio.regions)#
#
iberia.points@data$NewRegion <- overlap$Area_code#
iberia.point.var <- spTransform(iberia.points, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))#
iberia.data <- data.frame(iberia.points)#
iberia.data$Site <- as.character(iberia.data$Site)#
iberia.data2 <- data.frame(iberia.point.var)#
iberia.data2$NewRegion <- as.character(iberia.data2$NewRegion)#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SW", "Southwest")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SE", "Southeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="Mediterranean", "Northeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="North", "Northwest")#
iberia.col <- collapse.the.dates.new(sites=iberia.data2$Site, region=iberia.data2$NewRegion, context=iberia.data2$Type, lat=iberia.data2$Latitude, long=iberia.data2$Longitude, dates=iberia.data2$Date, sigma=iberia.data2$Sigma, datemin=1000, datemax=14000)
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))
####################################################
#######Calibration & Confidence Band Function#######
####################################################
#
###Multicore apply function with status bar#
mcpblapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    if (!is.vector(X) || is.object(X))#
    X <- as.list(X)#
    B <- length(X)#
    if (!(interactive() && dopb() && B >= 1))#
    return(mclapply(X, FUN, ...#
    ))#
    pb <- startpb(0, B)#
    rval <- vector("list", B)#
    for (i in 1:B) {#
        rval[i] <- list(FUN(X[[i]], ...))#
        setpb(pb, i)#
    }#
    close(pb)#
    names(rval) <- names(X)#
    rval#
}#
#
mcpbsapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    answer <- mcpblapply(X = X, FUN = FUN,  ..., USE.NAMES = TRUE)#
    if (USE.NAMES && is.character(X) && is.null(names(answer)))#
    names(answer) <- X#
    if (!identical(simplify, FALSE) && length(answer))#
    simplify2array(answer, higher = (simplify == "array"))#
    else answer#
}#
#
mcreplicate <- function(n, expr, simplify = "array", mc.cores = getOption("mc.cores", 2L)) {#
#
mcpbsapply(integer(n), eval.parent(substitute(function(...) expr)), mc.cores = getOption("mc.cores", 2L),#
simplify = simplify)#
#
}#
conf.loess <- function(x, sigma, n, reps, xmin, xmax) { #
samp.intcal <- rep("intcal13", length(x))#
samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
samp.ages <- ldply(samp.slugdens, data.frame)#
res.by <- by(samp.ages$ageGrid, samp.ages$.id, median) #
res.t <- t(res.by)#
samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
time <- seq(xmin+5, xmax-5, 10)#
samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
samp.hist <- hist(samp.grid, breaks=length(time))#
samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
colnames(samp.hist) <- c("Age", "Counts", "Density")#
#samp.hist <- arrange(samp.all, desc(Age))#
#
makeloess <- function(x, n){#
time <- seq(xmin+5, xmax-5, 10)#
samp.age <- sample(x, size=n, replace=TRUE)#
samp.dist <- sapply(1:n, function(x) rnorm(500, samp.age, 85))#
samp.dist <- as.vector(samp.dist)#
samp.dist <- c(xmax, xmin, samp.dist)#
samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
samp.loess <- lowess(time, samp.date, f=0.15)#
samp.fitted <- samp.loess$y#
return(samp.fitted)#
}#
#
samp.replicate <- (replicate(reps, makeloess(res.t, n)))#
samp.replicate <- as.data.frame(samp.replicate)#
samp.replicate[is.na(samp.replicate)] <- 0#
samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
#
samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
#
samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
#samp.descriptive <- arrange(samp.descriptive, desc(Age))#
samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
names(samp.all)[names(samp.all)=="time"] <- "Age"#
names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
samp.all <- arrange(samp.all, desc(Age))#
return(samp.all)#
}#
#
d#
fmt <- function(){#
    function(x) format(x,nsmall = 4,scientific = FALSE)#
}#
###Traditional SCDPD#
BchronDensityCollapse <- function (dates, sigma, sites,  dfs = rep(100, length(dates)), numMix = 30,#
iterations = 10000, burn = 2000, thin = 8, updateAges = FALSE, collapse.dates=FALSE)#
{#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    pathToCalCurves = system.file("data",#
    package = "Bchron")#
    calCurves <- rep("intcal13", length(date.data$Date))#
    ages <- date.data$Date#
    ageSds <- date.data$Sigma#
    if (length(ages) != length(ageSds))#
    stop("ages and 1-sigma errors must be same length")#
    if (length(ages) != length(calCurves))#
    stop("ages and Calibration curves must be same length")#
    x = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, eps = 0, dfs = rep(100,#
    length(ages)))#
    xSmall = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, dfs = rep(100, length(ages)))#
    n = length(x)#
    thetaRange = range(xSmall[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, xSmall[[i]]$ageGrid))#
    offset = vector(length = n)#
    for (i in 1:n) {#
        offset[i] = ifelse(x[[i]]$calCurve == "normal", 61, 0)#
    }#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    clrInv = function(phi) {#
        return(exp(phi)/sum(exp(phi)))#
    }#
    J = numMix#
    mu = seq(thetaRange[1], thetaRange[2], length = numMix)#
    theta = vector(length = n)#
    for (j in 1:n) theta[j] = round(stats::rnorm(1, mean = x[[j]]$ageGrid[match(max(x[[j]]$densities),#
    x[[j]]$densities)], sd = ageSds[j]), 3)#
    phi = c(stats::runif(J - 1, -10, 10), 0)#
    p = as.numeric(clrInv(phi))#
    G = gbase(theta, mu)#
    remaining = (iterations - burn)/thin#
    thetaStore = matrix(ncol = length(theta), nrow = remaining)#
    pStore = matrix(ncol = J, nrow = remaining)#
    thetaAll = matrix(NA, ncol = n, nrow = iterations)#
    for (j in 1:n) thetaAll[, j] = sample(xSmall[[j]]$ageGrid,#
    size = iterations, prob = xSmall[[j]]$densities, replace = TRUE)#
    mu2 = mu#
    sigma2 = (mu[2] - mu[1])/2#
    my_dnorm = function(x) stats::dnorm(x, mean = mu2, sd = sigma2)#
    pb = utils::txtProgressBar(min = 1, max = iterations, style = 3,#
    width = 60, title = "Running BchronDensity")#
    for (i in 1:iterations) {#
        utils::setTxtProgressBar(pb, i)#
        if (i > burn & i%%thin == 0) {#
            ind = (i - burn)/thin#
            thetaStore[ind, ] = theta#
            pStore[ind, ] = p#
        }#
        if (updateAges) {#
            for (j in 1:n) {#
                thetaNew = round(stats::rnorm(1, theta[j], 0.5),#
                3)#
                thetaNewMatch = as.integer(thetaNew + offset[j]) +#
                1#
                thetaNewLogDens = max(log(x[[j]]$densities[thetaNewMatch]),#
                -1e+06)#
                priorNew.dens = sum(p * stats::dnorm(thetaNew,#
                mean = mu2, sd = sigma2))#
                thetaMatch = as.integer(theta[j] + offset[j]) +#
                1#
                thetaLogDens = max(log(x[[j]]$densities[thetaMatch]),#
                -1e+06)#
                priorDens = sum(p * stats::dnorm(theta[j], mean = mu2,#
                sd = sigma2))#
                logRtheta = thetaNewLogDens - thetaLogDens +#
                log(priorNew.dens) - log(priorDens)#
                if (stats::runif(1) < exp(logRtheta))#
                theta[j] = thetaNew#
            }#
        }#
        else {#
            theta = thetaAll[i, ]#
        }#
        for (j in 1:(J - 1)) {#
            phiNew = stats::rnorm(1, phi[j], 1)#
            phiAllNew = phi#
            phiAllNew[j] = phiNew#
            pNew = as.numeric(clrInv(phiAllNew))#
            phiNewLogDens = sum(log(G %*% pNew))#
            phiLogDens = sum(log(G %*% p))#
            logRphi = phiNewLogDens - phiLogDens + stats::dunif(phiNew,#
            -10, 10, log = TRUE) - stats::dunif(phi[j], -10,#
            10, log = TRUE)#
            if (stats::runif(1) < exp(logRphi)) {#
                phi[j] = phiNew#
                p = as.numeric(clrInv(phi))#
            }#
        }#
    }#
    output = list(theta = thetaStore, p = pStore, mu = mu, calAges = xSmall,#
    G = G)#
    class(output) = "BchronDensityRun"#
    return(output)#
}#
#
###Function to modify existing SCDPD from BchronDensity (modified from Bchron)#
SlugDens.t <- function (x, xmin, xmax)#
{#
    n = length(x$calAges)#
    thetaRange = range(x$calAges[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, x$calAges[[i]]$ageGrid))#
    dateGrid = seq(xmin, xmax, length = 1000)#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    Gstar = gbase(dateGrid, x$mu)#
    dens = vector(length = length(dateGrid))#
    for (i in 1:nrow(x$p)) {#
        dens = dens + Gstar %*% x$p[i, ]#
    }#
    densFinal = dens/sum(dens)#
    slugbase <- data.frame(dateGrid,densFinal)#
    colnames(slugbase) <- c("Age", "Density")#
    slugbase <- arrange(slugbase, desc(Age))#
    return(slugbase)#
}#
#
SlugSig <- function(x, sigma, n, reps, xmin, xmax) {#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronDensity(x, sigma, samp.intcal, numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
    samp.hist <- SlugDens.t(samp.slugdens, xmin, xmax)#
    makeloess <- function(x, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.14C <- sample(x, size=n, replace=TRUE)#
        samp.sig <- sample(sigma, size=n, replace=TRUE)#
        samp.dist.n <- BchronDensity(samp.14C, samp.sig, rep("intcal13", n), numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
          samp.dist <- SlugDens.t(samp.dist.n, xmin, xmax)#
        samp.loess <- lowess(samp.dist$Age, samp.dist$Density, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(x, n)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(samp.hist$Age, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(samp.hist$Age, samp.hist$Density, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="samp.hist.Age"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
######Function to Generate Confidence Bands around SCDRD#
conf.cal.loess.old <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+1, xmax, 1)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.grid <- c(fill, samp.grid)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+1, xmax, 1)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(fill, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.cal.loess.trad <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.loess <- function(dates, sigma, sites, n, reps, xmin, xmax) {#
    samp.intcal <- rep("intcal13", length(dates))#
    samp.slugdens <- BchronCalibrate(dates, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    small.age.frame <- data.frame(samp.ages$.id, as.vector(samp.ages$ageGrid), as.vector(samp.ages$ageSds))#
    colnames(small.age.frame) <- c("Id", "ageGrid", "ageSDS")#
    samp.test <- aggregate(small.age.frame[,2:3], by=list(small.age.frame$Id), FUN=median)#
    colnames(samp.test) <- c("Id", "Mean", "SD")#
    samp.test$Min <- samp.test$Mean-samp.test$SD#
    samp.test$Max <- samp.test$Mean+samp.test$SD#
    samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
    samp.age.grid <- subset(samp.age.grid, !(xmin > samp.age.grid | samp.age.grid > xmax))#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(c(samp.grid, xmin, xmax), breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(a.frame, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.id <- as.vector(sample(as.vector(a.frame$Id), size=n, replace=TRUE))#
        t.frame <- data.frame(t(a.frame))#
        colnames(t.frame) <- a.frame$Id#
        s.t.frame <- t.frame[,samp.id]#
        f.frame <- data.frame(t(s.t.frame))#
        #f.frame <- data.table(f.frame)#
        small.frame <- data.frame(f.frame$Id, f.frame$Min, f.frame$Max)#
        colnames(small.frame) <- c("Id", "Min", "Max")#
        small.list <- split(as.vector(small.frame[,2:3]), f=small.frame$Id)#
        small.list <- lapply(small.list, function(x) as.vector(x[1,]))#
        seq.gen <- function(a.frame) {#
            a.frame <- as.data.frame(a.frame)#
            at.vector <- as.numeric(as.vector(as.data.frame(t(a.frame))[,1]))#
            sequence <- seq(from=at.vector[1], to=at.vector[2], by=1)#
            return(sequence)#
        }#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- ldply(all.seq, data.frame)[,2]#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- as.vector(tapply(samp.dist, cut(samp.dist, length(time)), length))#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- as.vector(ldply(all.seq, data.frame)[,2])#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(samp.test, reps)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
stack.14C.taxa.old <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
stack.14C.taxa <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma*2#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma*2#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
#######
stack.14C <- function(x, sigma, xmin, xmax, taxa){#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
taphonomic.correct <- function(stack.14C.data) {#
    df <- stack.14C.data#
    n.t <- 5.726442*(10^6)*(df$Age + 2176.4)^-1.3925309#
    lambda <- 1.3925309/(2176.4+df$Age)*100#
    lambda.r <- 1-lambda#
    n.t.relative <- n.t/128.8192#
    df$Counts.Corrected <-df$Counts/n.t.relative#
    count.mod.sum <- sum(df$Counts.Corrected)#
    df$Density.Corrected <- df$Counts.Corrected/count.mod.sum#
    return(df)#
}#
criterion.data.null <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !stack.14C.taxa.object$Taxa==criteria.names)#
    ageGrids <- c(temp.df.1$ageGrid, temp.df.2$ageGrid)#
    Taxa <- c(as.vector(temp.df.1$Taxa), rep("Other", length(temp.df.2$ageGrid)))#
    temp.df <- data.frame(ageGrids, Taxa)#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
criterion.data.old <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, corrected.samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)), even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    colnames(temp.df.alt) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    temp.list.alt <- split(temp.df.alt$ageGrid, f=temp.df.alt$Taxa)#
    temp.list.alt <- rapply(temp.list.alt, f=sort, how="list", decreasing=TRUE)#
    samp.hist.list.alt <- rapply(temp.list.alt, f=hist, how="list", breaks=length(time))#
    samp.mids.alt <- sapply(samp.hist.list.alt, "[[", 4)#
    samp.counts.alt <- sapply(samp.hist.list.alt, "[[", 2)#
    samp.density.alt <- sapply(samp.hist.list.alt, "[[", 3)#
    samp.mids.df.alt <- ldply(samp.mids.alt, data.frame)#
    samp.counts.df.alt <- ldply(samp.counts.alt, data.frame)#
    samp.density.df.alt <- ldply(samp.density.alt, data.frame)#
    hist.alt <- hist(temp.df.alt$ageGrid, breaks=length(time))#
    samp.mids.alt <- hist.alt$mids#
    samp.counts.alt <- hist.alt$counts#
    count.sum <- sum(samp.counts.alt)#
    samp.density.alt <- hist.alt$density#
    samp.names.alt <- rep("Total", length(samp.mids.alt))#
    samp.hist <- data.frame(c(samp.mids.df[,1], samp.names.alt), as.numeric(as.vector(c(samp.mids.df[,2], samp.mids.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt)))/count.sum)#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)),#
        as.numeric(as.vector(even.more.corrected.samp.hist$Freq))/count.sum,#
        even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Density", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data.test <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    df <- data.frame(c(temp.df.1$ageGrid, temp.df.2$ageGrid), c(as.vector(temp.df.1$Taxa), rep("Total", length(temp.df.2$ageGrid))))#
    colnames(df) <- c("ageGrid", "Taxa")#
    return(df)#
}#
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
    intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
####Taxa Analysis#
northwest.stack <- stack.14C.taxa(date=northwest.14C, sigma=northwest.sig, xmin=0, xmax=12000, lat=northwest.lat, long=northwest.long, taxa=northwest.taxa)#
southwest.stack <- stack.14C.taxa(date=southwest.14C, sigma=southwest.sig, xmin=2000, xmax=12000, lat=southwest.lat, long=southwest.long, taxa=southwest.taxa)#
southeast.stack <- stack.14C.taxa(date=southeast.14C, sigma=southeast.sig, xmin=2000, xmax=12000, lat=southeast.lat, long=southeast.long, taxa=southeast.taxa)#
meseta.stack <- stack.14C.taxa(date=meseta.14C, sigma=meseta.sig, xmin=2000, xmax=12000, lat=meseta.lat, long=meseta.long, taxa=meseta.taxa)#
northeast.stack <- stack.14C.taxa(date=northeast.14C, sigma=northeast.sig, xmin=2000, xmax=12000, lat=northeast.lat, long=northeast.long, taxa=northeast.taxa)#
#
northwest.criterion <- criterion.data(northwest.stack, criteria.names=c("Mortuary", "Settlement"), xmin=0, xmax=12000)#
southwest.criterion <- criterion.data(southwest.stack, criteria.names=c("Mortuary",  "Settlement"), xmin=0, xmax=12000)#
southeast.criterion <- criterion.data(southeast.stack, criteria.names=c("Mortuary",  "Settlement"), xmin=0, xmax=12000)#
meseta.criterion <- criterion.data(meseta.stack, criteria.names=c("Mortuary", "Settlement"), xmin=0, xmax=12000)#
northeast.criterion <- criterion.data(northeast.stack, criteria.names=c("Mortuary",  "Settlement"), xmin=0, xmax=12000)#
#
northwest.criterion$Taxa <- factor(northwest.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))
#####Plots#
northwest.sub.plot <- ggplot(northwest.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)
northwest.sub.plot
quartz()
northwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(northwest.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=rev(Taxa), position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
northwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(northwest.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
northwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, Taxa)) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
northwest.sub.plot
?arrange
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .2, end = .8, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
northwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
#ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
northwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
southwest.sub.plot <- ggplot(southwest.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=Taxa, fill=Taxa), position="stack") +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Southwest")#
ggsave(southwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure18.tiff", dpi=300, device="tiff", width=10, height=7)#
southeast.sub.plot <- ggplot(southeast.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=Taxa, fill=Taxa), position="stack") +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Southeast")#
ggsave(southeast.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure20.tiff", dpi=300, device="tiff", width=10, height=7)#
meseta.sub.plot <- ggplot(meseta.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=Taxa, fill=Taxa), position="stack") +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Meseta")#
ggsave(meseta.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure9.tiff", dpi=300, device="tiff", width=10, height=7)#
northeast.sub.plot <- ggplot(northeast.criterion) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=Taxa, fill=Taxa), position="stack") +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northeast")#
ggsave(northeast.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure16.tiff", dpi=300, device="tiff", width=10, height=7)
northeast.sub.plot <- ggplot(arrange(northeast.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northeast")
northeast.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)
northwest.sub.plot
northwest.criterion$Taxa <- factor(northwest.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))#
southwest.criterion$Taxa <- factor(southwest.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))#
southeast.criterion$Taxa <- factor(southeast.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))#
meseta.criterion$Taxa <- factor(meseta.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))#
northeast.criterion$Taxa <- factor(northeast.criterion$Taxa, levels = c("Total", "Settlement", "Mortuary"))
southwest.sub.plot <- ggplot(arrange(southwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Southwest")#
ggsave(southwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure18.tiff", dpi=300, device="tiff", width=10, height=7)
southwest.sub.plot
#####Plots#
northwest.sub.plot <- ggplot(arrange(northwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northwest")#
ggsave(northwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure8.tiff", dpi=300, device="tiff", width=10, height=7)#
southwest.sub.plot <- ggplot(arrange(southwest.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Southwest")#
ggsave(southwest.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure18.tiff", dpi=300, device="tiff", width=10, height=7)#
southeast.sub.plot <- ggplot(arrange(southeast.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Southeast")#
ggsave(southeast.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure20.tiff", dpi=300, device="tiff", width=10, height=7)#
meseta.sub.plot <- ggplot(arrange(meseta.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Meseta")#
ggsave(meseta.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure9.tiff", dpi=300, device="tiff", width=10, height=7)#
northeast.sub.plot <- ggplot(arrange(northeast.criterion, desc(Taxa))) +#
theme_light() +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
geom_area(aes(x=Age, y=Density,  colour=factor(Taxa), fill=factor(Taxa), order=Taxa, position="stack")) +#
scale_x_reverse("Year BC", limits = c(5000, 1000), breaks = seq(1000, 5000, 500)) +#
scale_y_continuous("Density", labels=fmt()) +#
theme(legend.position=c(0.025, .975), legend.justification=c(0,1), legend.background = element_rect(colour = "white", fill = "white")) +#
guides(fill=guide_legend(title="Site Type"), colour=guide_legend(title="Site Type")) +#
scale_fill_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
scale_colour_grey(start = .8, end = .2, guide=guide_legend(reverse=TRUE)) +#
geom_vline(aes(xintercept = abs(2200)), colour="black", linetype=2)+#
geom_vline(aes(xintercept = abs(2000)), colour="black", linetype=2)+#
ggtitle("Northeast")#
ggsave(northeast.sub.plot, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure16.tiff", dpi=300, device="tiff", width=10, height=7)
head(iberia.col)
length(northwest.sig)
iberia.col <- subset(iberia.col, CYrBPunc < 5500)
iberia.col <- subset(iberia.col, CYrBPunc > 500)
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")
length(northwest.sig)
length(southwest.sig)
iberia.data2
ls(iberia.data2)
iberia.data <- subset(iberia.data2, iberia.data2$Date < 5500)
iberia.data <- subset(iberia.data2, iberia.data2$Date > 500)
length(iberia.data[1])
length(iberia.data$Date)
length(subset(iberia.data$Date, ))
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
#Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
#packrat::init("~/Dropbox/4.2 ky event/Data Analysis/R Code/For Distribution/Neolithic")#
#
#Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###Load Packages#
library(TTR)#
library(ggplot2)#
library(gridExtra)#
library(scales)#
library(gtable)#
library(wq)#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape)#
library(sp)#
library(raster)#
library(rgdal)#
library(rgeos)#
library(maptools)#
library(sp)#
library(spatialEco)#
#
###Load Packages#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape2)#
library(pbapply)#
library(xlsx)#
library(data.table)#
library(dplyr)#
library(akima)#
library(ggmap)#
library(ggthemes)#
#
###Download Packages (if needed) at http://www.bleedrake.com/Neolithic/Neolithic.zip#
#
###Load Data#
neolithic.bio <- read.csv(file="http://www.bleedrake.com/Neolithic/neolithic.csv")#
all.data <- read.csv(file="~/Dropbox/4.2 ky event/Radiocarbon Final/All Iberia/Just Dates-1-Table 1.csv")#
#
###Load Calibration Curves#
intcal.13 <- read.csv(file="http://www.bleedrake.com/Neolithic/intcal13.csv")#
#####Collapse Dates#
collapse.the.dates.begin <- function(sites, biogeo, general, dates, sigma) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, biogeo, general, dates, sigma)#
    colnames(df) <- c("Site", "Biogeo_Uni", "St_Area_NE", "CYrBPunc", "Sigma")#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Biogeo_Uni))#
    df <- arrange(df, desc(St_Area_NE))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),4]-df[2:nrow(df), 4]))/((sqrt(df[2:nrow(df), 5]^2 + df[1:(nrow(df)-1),5]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),6], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(sites))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
#####Collapse Dates#
collapse.the.dates.new <- function(sites, region, context, dates, sigma, lat, long, datemin, datemax) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, region, context, lat, long, as.numeric(dates), as.numeric(sigma))#
    colnames(df) <- c("Site", "Region", "Context", "Lat", "Long", "CYrBPunc", "Sigma")#
    df <- subset(df, df$CYrBPunc < datemax & df$CYrBPunc > datemin)#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Region))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),6]-df[2:nrow(df), 6]))/((sqrt(df[2:nrow(df), 7]^2 + df[1:(nrow(df)-1),7]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),8], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(df$Site))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
neolithic.bio <- collapse.the.dates.begin(sites=neolithic.bio$Site, biogeo=neolithic.bio$Biogeo_Uni, general=neolithic.bio$St_Area_NE, dates=neolithic.bio$CYrBPunc, sigma=neolithic.bio$Sigma)#
#####Intersect 14C dates by region#
antonio.regions <- readOGR("/Users/lee/Dropbox/4.2 ky event/jwp paper/Event42_areasIberia", "Event42_areasIberia")#
antonio.p1 <- as(antonio.regions, "SpatialPolygons")#
antonio.p1@data$id = rownames(antonio.p1@data)#
#
small.frame <- data.frame(all.data$Region, all.data$Site, all.data$Site.Type, all.data$Site.Type.Simple, all.data$Context..phase..etc.., all.data$Lat.in.Dec, all.data$Long.in.Dec, all.data$Sample.Lab.Number, all.data$X14C.Yr.BP.uncal, all.data$Sigma)#
colnames(small.frame) <- c("Region", "Site", "Details", "Type", "Context", "Latitude", "Longitude", "LabNumber", "Date", "Sigma")#
small.frame <- small.frame[!(is.na(small.frame$Latitude) | small.frame$Latitude==""), ]#
small.frame <- small.frame[!(is.na(small.frame$Longitude) | small.frame$Longitude==""), ]#
small.frame$Region <- sub("^$", "0", small.frame$Region)#
small.frame$Site <- sub("^$", "0", small.frame$Site)#
small.frame$Type <- sub("^$", "0", small.frame$Type)#
small.frame$Context <- sub("^$", "0", small.frame$Context)#
small.frame$LabNumber <- sub("^$", "0", small.frame$LabNumber)#
small.frame$Date <- sub("^$", "0", small.frame$Date)#
small.frame$Sigma <- sub("^$", "0", small.frame$Sigma)#
iberia.points <- data.frame(small.frame)#
#
coordinates(iberia.points) = ~Longitude+Latitude#
proj4string(iberia.points) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0")#
#
iberia.points <- spTransform(iberia.points, CRS("+proj=utm +zone=30 +ellps=GRS80 +units=m +no_defs"))#
#
overlap <- over(iberia.points, antonio.regions)#
#
iberia.points@data$NewRegion <- overlap$Area_code#
iberia.point.var <- spTransform(iberia.points, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))#
iberia.data <- data.frame(iberia.points)#
iberia.data$Site <- as.character(iberia.data$Site)#
iberia.data2 <- data.frame(iberia.point.var)#
iberia.data2$NewRegion <- as.character(iberia.data2$NewRegion)#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SW", "Southwest")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SE", "Southeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="Mediterranean", "Northeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="North", "Northwest")#
iberia.col <- collapse.the.dates.new(sites=iberia.data2$Site, region=iberia.data2$NewRegion, context=iberia.data2$Type, lat=iberia.data2$Latitude, long=iberia.data2$Longitude, dates=iberia.data2$Date, sigma=iberia.data2$Sigma, datemin=1000, datemax=14000)#
#
spain <- get_map(location="Spain", zoom=6, maptype="terrain")#
#
Fig4 <- ggmap(spain, alpha=0.2) +#
geom_point(data=iberia.col, aes(x=Long, y=Lat, colour=Region, shape=Region), size=3, alpha=0.4)+#
coord_equal() +#
coord_map() +#
theme_tufte() +#
scale_x_continuous("Longitude") +#
scale_y_continuous("Latitude") +#
guides(size=FALSE, alpha=FALSE)#
#
ggsave(Fig4, , file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/Figure 4.tiff", dpi=300, device="tiff")#
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))#
#
####################################################
#######Calibration & Confidence Band Function#######
####################################################
#
###Multicore apply function with status bar#
mcpblapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    if (!is.vector(X) || is.object(X))#
    X <- as.list(X)#
    B <- length(X)#
    if (!(interactive() && dopb() && B >= 1))#
    return(mclapply(X, FUN, ...#
    ))#
    pb <- startpb(0, B)#
    rval <- vector("list", B)#
    for (i in 1:B) {#
        rval[i] <- list(FUN(X[[i]], ...))#
        setpb(pb, i)#
    }#
    close(pb)#
    names(rval) <- names(X)#
    rval#
}#
#
mcpbsapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    answer <- mcpblapply(X = X, FUN = FUN,  ..., USE.NAMES = TRUE)#
    if (USE.NAMES && is.character(X) && is.null(names(answer)))#
    names(answer) <- X#
    if (!identical(simplify, FALSE) && length(answer))#
    simplify2array(answer, higher = (simplify == "array"))#
    else answer#
}#
#
mcreplicate <- function(n, expr, simplify = "array", mc.cores = getOption("mc.cores", 2L)) {#
#
mcpbsapply(integer(n), eval.parent(substitute(function(...) expr)), mc.cores = getOption("mc.cores", 2L),#
simplify = simplify)#
#
}#
conf.loess <- function(x, sigma, n, reps, xmin, xmax) { #
samp.intcal <- rep("intcal13", length(x))#
samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
samp.ages <- ldply(samp.slugdens, data.frame)#
res.by <- by(samp.ages$ageGrid, samp.ages$.id, median) #
res.t <- t(res.by)#
samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
time <- seq(xmin+5, xmax-5, 10)#
samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
samp.hist <- hist(samp.grid, breaks=length(time))#
samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
colnames(samp.hist) <- c("Age", "Counts", "Density")#
#samp.hist <- arrange(samp.all, desc(Age))#
#
makeloess <- function(x, n){#
time <- seq(xmin+5, xmax-5, 10)#
samp.age <- sample(x, size=n, replace=TRUE)#
samp.dist <- sapply(1:n, function(x) rnorm(500, samp.age, 85))#
samp.dist <- as.vector(samp.dist)#
samp.dist <- c(xmax, xmin, samp.dist)#
samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
samp.loess <- lowess(time, samp.date, f=0.15)#
samp.fitted <- samp.loess$y#
return(samp.fitted)#
}#
#
samp.replicate <- (replicate(reps, makeloess(res.t, n)))#
samp.replicate <- as.data.frame(samp.replicate)#
samp.replicate[is.na(samp.replicate)] <- 0#
samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
#
samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
#
samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
#samp.descriptive <- arrange(samp.descriptive, desc(Age))#
samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
names(samp.all)[names(samp.all)=="time"] <- "Age"#
names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
samp.all <- arrange(samp.all, desc(Age))#
return(samp.all)#
}#
#
d#
fmt <- function(){#
    function(x) format(x,nsmall = 4,scientific = FALSE)#
}#
###Traditional SCDPD#
BchronDensityCollapse <- function (dates, sigma, sites,  dfs = rep(100, length(dates)), numMix = 30,#
iterations = 10000, burn = 2000, thin = 8, updateAges = FALSE, collapse.dates=FALSE)#
{#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    pathToCalCurves = system.file("data",#
    package = "Bchron")#
    calCurves <- rep("intcal13", length(date.data$Date))#
    ages <- date.data$Date#
    ageSds <- date.data$Sigma#
    if (length(ages) != length(ageSds))#
    stop("ages and 1-sigma errors must be same length")#
    if (length(ages) != length(calCurves))#
    stop("ages and Calibration curves must be same length")#
    x = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, eps = 0, dfs = rep(100,#
    length(ages)))#
    xSmall = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, dfs = rep(100, length(ages)))#
    n = length(x)#
    thetaRange = range(xSmall[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, xSmall[[i]]$ageGrid))#
    offset = vector(length = n)#
    for (i in 1:n) {#
        offset[i] = ifelse(x[[i]]$calCurve == "normal", 61, 0)#
    }#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    clrInv = function(phi) {#
        return(exp(phi)/sum(exp(phi)))#
    }#
    J = numMix#
    mu = seq(thetaRange[1], thetaRange[2], length = numMix)#
    theta = vector(length = n)#
    for (j in 1:n) theta[j] = round(stats::rnorm(1, mean = x[[j]]$ageGrid[match(max(x[[j]]$densities),#
    x[[j]]$densities)], sd = ageSds[j]), 3)#
    phi = c(stats::runif(J - 1, -10, 10), 0)#
    p = as.numeric(clrInv(phi))#
    G = gbase(theta, mu)#
    remaining = (iterations - burn)/thin#
    thetaStore = matrix(ncol = length(theta), nrow = remaining)#
    pStore = matrix(ncol = J, nrow = remaining)#
    thetaAll = matrix(NA, ncol = n, nrow = iterations)#
    for (j in 1:n) thetaAll[, j] = sample(xSmall[[j]]$ageGrid,#
    size = iterations, prob = xSmall[[j]]$densities, replace = TRUE)#
    mu2 = mu#
    sigma2 = (mu[2] - mu[1])/2#
    my_dnorm = function(x) stats::dnorm(x, mean = mu2, sd = sigma2)#
    pb = utils::txtProgressBar(min = 1, max = iterations, style = 3,#
    width = 60, title = "Running BchronDensity")#
    for (i in 1:iterations) {#
        utils::setTxtProgressBar(pb, i)#
        if (i > burn & i%%thin == 0) {#
            ind = (i - burn)/thin#
            thetaStore[ind, ] = theta#
            pStore[ind, ] = p#
        }#
        if (updateAges) {#
            for (j in 1:n) {#
                thetaNew = round(stats::rnorm(1, theta[j], 0.5),#
                3)#
                thetaNewMatch = as.integer(thetaNew + offset[j]) +#
                1#
                thetaNewLogDens = max(log(x[[j]]$densities[thetaNewMatch]),#
                -1e+06)#
                priorNew.dens = sum(p * stats::dnorm(thetaNew,#
                mean = mu2, sd = sigma2))#
                thetaMatch = as.integer(theta[j] + offset[j]) +#
                1#
                thetaLogDens = max(log(x[[j]]$densities[thetaMatch]),#
                -1e+06)#
                priorDens = sum(p * stats::dnorm(theta[j], mean = mu2,#
                sd = sigma2))#
                logRtheta = thetaNewLogDens - thetaLogDens +#
                log(priorNew.dens) - log(priorDens)#
                if (stats::runif(1) < exp(logRtheta))#
                theta[j] = thetaNew#
            }#
        }#
        else {#
            theta = thetaAll[i, ]#
        }#
        for (j in 1:(J - 1)) {#
            phiNew = stats::rnorm(1, phi[j], 1)#
            phiAllNew = phi#
            phiAllNew[j] = phiNew#
            pNew = as.numeric(clrInv(phiAllNew))#
            phiNewLogDens = sum(log(G %*% pNew))#
            phiLogDens = sum(log(G %*% p))#
            logRphi = phiNewLogDens - phiLogDens + stats::dunif(phiNew,#
            -10, 10, log = TRUE) - stats::dunif(phi[j], -10,#
            10, log = TRUE)#
            if (stats::runif(1) < exp(logRphi)) {#
                phi[j] = phiNew#
                p = as.numeric(clrInv(phi))#
            }#
        }#
    }#
    output = list(theta = thetaStore, p = pStore, mu = mu, calAges = xSmall,#
    G = G)#
    class(output) = "BchronDensityRun"#
    return(output)#
}#
#
###Function to modify existing SCDPD from BchronDensity (modified from Bchron)#
SlugDens.t <- function (x, xmin, xmax)#
{#
    n = length(x$calAges)#
    thetaRange = range(x$calAges[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, x$calAges[[i]]$ageGrid))#
    dateGrid = seq(xmin, xmax, length = 1000)#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    Gstar = gbase(dateGrid, x$mu)#
    dens = vector(length = length(dateGrid))#
    for (i in 1:nrow(x$p)) {#
        dens = dens + Gstar %*% x$p[i, ]#
    }#
    densFinal = dens/sum(dens)#
    slugbase <- data.frame(dateGrid,densFinal)#
    colnames(slugbase) <- c("Age", "Density")#
    slugbase <- arrange(slugbase, desc(Age))#
    return(slugbase)#
}#
#
SlugSig <- function(x, sigma, n, reps, xmin, xmax) {#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronDensity(x, sigma, samp.intcal, numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
    samp.hist <- SlugDens.t(samp.slugdens, xmin, xmax)#
    makeloess <- function(x, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.14C <- sample(x, size=n, replace=TRUE)#
        samp.sig <- sample(sigma, size=n, replace=TRUE)#
        samp.dist.n <- BchronDensity(samp.14C, samp.sig, rep("intcal13", n), numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
          samp.dist <- SlugDens.t(samp.dist.n, xmin, xmax)#
        samp.loess <- lowess(samp.dist$Age, samp.dist$Density, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(x, n)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(samp.hist$Age, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(samp.hist$Age, samp.hist$Density, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="samp.hist.Age"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
######Function to Generate Confidence Bands around SCDRD#
conf.cal.loess.old <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+1, xmax, 1)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.grid <- c(fill, samp.grid)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+1, xmax, 1)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(fill, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.cal.loess.trad <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.loess <- function(dates, sigma, sites, n, reps, xmin, xmax) {#
    samp.intcal <- rep("intcal13", length(dates))#
    samp.slugdens <- BchronCalibrate(dates, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    small.age.frame <- data.frame(samp.ages$.id, as.vector(samp.ages$ageGrid), as.vector(samp.ages$ageSds))#
    colnames(small.age.frame) <- c("Id", "ageGrid", "ageSDS")#
    samp.test <- aggregate(small.age.frame[,2:3], by=list(small.age.frame$Id), FUN=median)#
    colnames(samp.test) <- c("Id", "Mean", "SD")#
    samp.test$Min <- samp.test$Mean-samp.test$SD#
    samp.test$Max <- samp.test$Mean+samp.test$SD#
    samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
    samp.age.grid <- subset(samp.age.grid, !(xmin > samp.age.grid | samp.age.grid > xmax))#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(c(samp.grid, xmin, xmax), breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(a.frame, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.id <- as.vector(sample(as.vector(a.frame$Id), size=n, replace=TRUE))#
        t.frame <- data.frame(t(a.frame))#
        colnames(t.frame) <- a.frame$Id#
        s.t.frame <- t.frame[,samp.id]#
        f.frame <- data.frame(t(s.t.frame))#
        #f.frame <- data.table(f.frame)#
        small.frame <- data.frame(f.frame$Id, f.frame$Min, f.frame$Max)#
        colnames(small.frame) <- c("Id", "Min", "Max")#
        small.list <- split(as.vector(small.frame[,2:3]), f=small.frame$Id)#
        small.list <- lapply(small.list, function(x) as.vector(x[1,]))#
        seq.gen <- function(a.frame) {#
            a.frame <- as.data.frame(a.frame)#
            at.vector <- as.numeric(as.vector(as.data.frame(t(a.frame))[,1]))#
            sequence <- seq(from=at.vector[1], to=at.vector[2], by=1)#
            return(sequence)#
        }#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- ldply(all.seq, data.frame)[,2]#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- as.vector(tapply(samp.dist, cut(samp.dist, length(time)), length))#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- as.vector(ldply(all.seq, data.frame)[,2])#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(samp.test, reps)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
stack.14C.taxa.old <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
stack.14C.taxa <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma*2#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma*2#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
#######
stack.14C <- function(x, sigma, xmin, xmax, taxa){#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
taphonomic.correct <- function(stack.14C.data) {#
    df <- stack.14C.data#
    n.t <- 5.726442*(10^6)*(df$Age + 2176.4)^-1.3925309#
    lambda <- 1.3925309/(2176.4+df$Age)*100#
    lambda.r <- 1-lambda#
    n.t.relative <- n.t/128.8192#
    df$Counts.Corrected <-df$Counts/n.t.relative#
    count.mod.sum <- sum(df$Counts.Corrected)#
    df$Density.Corrected <- df$Counts.Corrected/count.mod.sum#
    return(df)#
}#
criterion.data.null <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !stack.14C.taxa.object$Taxa==criteria.names)#
    ageGrids <- c(temp.df.1$ageGrid, temp.df.2$ageGrid)#
    Taxa <- c(as.vector(temp.df.1$Taxa), rep("Other", length(temp.df.2$ageGrid)))#
    temp.df <- data.frame(ageGrids, Taxa)#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
criterion.data.old <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, corrected.samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)), even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    colnames(temp.df.alt) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    temp.list.alt <- split(temp.df.alt$ageGrid, f=temp.df.alt$Taxa)#
    temp.list.alt <- rapply(temp.list.alt, f=sort, how="list", decreasing=TRUE)#
    samp.hist.list.alt <- rapply(temp.list.alt, f=hist, how="list", breaks=length(time))#
    samp.mids.alt <- sapply(samp.hist.list.alt, "[[", 4)#
    samp.counts.alt <- sapply(samp.hist.list.alt, "[[", 2)#
    samp.density.alt <- sapply(samp.hist.list.alt, "[[", 3)#
    samp.mids.df.alt <- ldply(samp.mids.alt, data.frame)#
    samp.counts.df.alt <- ldply(samp.counts.alt, data.frame)#
    samp.density.df.alt <- ldply(samp.density.alt, data.frame)#
    hist.alt <- hist(temp.df.alt$ageGrid, breaks=length(time))#
    samp.mids.alt <- hist.alt$mids#
    samp.counts.alt <- hist.alt$counts#
    count.sum <- sum(samp.counts.alt)#
    samp.density.alt <- hist.alt$density#
    samp.names.alt <- rep("Total", length(samp.mids.alt))#
    samp.hist <- data.frame(c(samp.mids.df[,1], samp.names.alt), as.numeric(as.vector(c(samp.mids.df[,2], samp.mids.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt)))/count.sum)#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)),#
        as.numeric(as.vector(even.more.corrected.samp.hist$Freq))/count.sum,#
        even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Density", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data.test <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    df <- data.frame(c(temp.df.1$ageGrid, temp.df.2$ageGrid), c(as.vector(temp.df.1$Taxa), rep("Total", length(temp.df.2$ageGrid))))#
    colnames(df) <- c("ageGrid", "Taxa")#
    return(df)#
}#
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
    intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}#
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
intcal.13 <- read.csv(file="~/Dropbox/Documents/SCDPD/First Round/Nature Submission/Supplemental Data/intcal13.csv")
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
head(northwest.med)
length(northwest.med$Median)
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=3300, xmin=1500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax= 3300, xmin= 1500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax= 3300, xmin= 1500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax= 3300, xmin= 1500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax= 3300, xmin= 1500)
north.med.site.count <- length(unique(north.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
med.med.site.count <- length(unique(med.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
northwest.med.site.count <- length(unique(northwest.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
northeast.med.site.count <- length(unique(northeast.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
length(northwest.med)
length(northwest.med$Median)
length(meseta.med$Median)
length(northeast.med$Median)
length(southwest.med$Median)
length(southeast.med$Median)
northwest.med.site.count
meseta.med.site.count
northeast.med.site.count
southwest.med.site.count
southeast.med.site.count
head(northwest.med)
table(northwest.med$Context)
table(meseta.med$Context)
table(northeast.med$Context)
table(southwest.med$Context)
table(southeast.med$Context)
ls(iberia.data2)
ls(iberia.col)
iberia.col <- iberia.data2
head(iberia.col)
colnames(iberia.col) <- c("Region", "Site", "Details", "Type", "Context", "LabNumber", "CYrBPunc", "Sigma", "NewRegion", "Longitude", "Latitude", "optional")
head(iberia.col)
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)#
northwest.med.site.count <- length(unique(northwest.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
northeast.med.site.count <- length(unique(northeast.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
head(northwest.sig)
head(iberia.col)
colnames(iberia.col) <- c("BadRegion", "Site", "Details", "Type", "Context", "LabNumber", "CYrBPunc", "Sigma", "NewRegion", "Longitude", "Latitude", "optional")
colnames(iberia.col) <- c("BadRegion", "Site", "Details", "Type", "Context", "LabNumber", "CYrBPunc", "Sigma", "Region", "Longitude", "Latitude", "optional")
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))
head(northwest.sig)
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)#
northwest.med.site.count <- length(unique(northwest.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
northeast.med.site.count <- length(unique(northeast.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=3300, xmin=1500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax= 3300, xmin= 1500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax= 3300, xmin= 1500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax= 3300, xmin= 1500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax= 3300, xmin= 1500)#
northwest.med.site.count <- length(unique(northwest.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
northeast.med.site.count <- length(unique(northeast.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
    temp.table <- data.frame(x, sigma, sites, context)#
    temp.table <- subset(temp.table, !(temp.table$x > 39999 | temp.table$s < 100))#
    x <- temp.table$x#
    sigma <- temp.table$sigma#
    sites <- temp.table$sites#
    context <- temp.table$context#
    intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
    temp.table <- data.frame(x, sigma, sites, context)#
    temp.table <- subset(temp.table, !(temp.table$x > 39999 | temp.table$x < 100))#
    x <- temp.table$x#
    sigma <- temp.table$sigma#
    sites <- temp.table$sites#
    context <- temp.table$context#
    intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
    temp.table <- data.frame(as.vector(as.numeric(x)), sigma, sites, context)#
    temp.table <- subset(temp.table, !(temp.table$x > 39999 | temp.table$x < 100))#
    x <- temp.table$x#
    sigma <- temp.table$sigma#
    sites <- temp.table$sites#
    context <- temp.table$context#
    intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
?BchronCalibrate
iberia.col <- subset(iberia.col, CYrBPunc < 39999)
iberia.col <- subset(iberia.col, CYrBPunc > 100)
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
      intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=3300, xmin=1500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax= 3300, xmin= 1500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax= 3300, xmin= 1500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax= 3300, xmin= 1500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax= 3300, xmin= 1500)#
northwest.med.site.count <- length(unique(northwest.med$Site))#
meseta.med.site.count <- length(unique(meseta.med$Site))#
northeast.med.site.count <- length(unique(northeast.med$Site))#
southwest.med.site.count <- length(unique(southwest.med$Site))#
southeast.med.site.count <- length(unique(southeast.med$Site))
length(northwest.med$Median)
length(meseta.met$Median)
length(meseta.med$Median)
length(northeast.med$Median)
length(southwest.med$Median)
length(southeast.med$Median)
library(shiny)
runApp("~/GitHub/5i Results App")
runApp("~/GitHub/xrf-app")
#Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
#packrat::init("~/Dropbox/4.2 ky event/Data Analysis/R Code/For Distribution/Neolithic")#
#
#Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###Load Packages#
library(TTR)#
library(ggplot2)#
library(gridExtra)#
library(scales)#
library(gtable)#
library(wq)#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape)#
library(sp)#
library(raster)#
library(rgdal)#
library(rgeos)#
library(maptools)#
library(sp)#
library(spatialEco)#
#
###Load Packages#
library(Bchron)#
library(plyr)#
library(bcp)#
#library(mgcv)#
library(reshape2)#
library(pbapply)#
library(xlsx)#
library(data.table)#
library(dplyr)#
library(akima)#
library(ggmap)#
library(ggthemes)#
#
###Download Packages (if needed) at http://www.bleedrake.com/Neolithic/Neolithic.zip#
#
###Load Data#
neolithic.bio <- read.csv(file="http://www.bleedrake.com/Neolithic/neolithic.csv")#
all.data <- read.csv(file="~/Dropbox/4.2 ky event/Radiocarbon Final/All Iberia/Just Dates-1-Table 1.csv")#
#
###Load Calibration Curves#
#intcal.13 <- read.csv(file="http://www.bleedrake.com/Neolithic/intcal13.csv")#
#####Collapse Dates#
collapse.the.dates.begin <- function(sites, biogeo, general, dates, sigma) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, biogeo, general, dates, sigma)#
    colnames(df) <- c("Site", "Biogeo_Uni", "St_Area_NE", "CYrBPunc", "Sigma")#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Biogeo_Uni))#
    df <- arrange(df, desc(St_Area_NE))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),4]-df[2:nrow(df), 4]))/((sqrt(df[2:nrow(df), 5]^2 + df[1:(nrow(df)-1),5]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),6], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(sites))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
#####Collapse Dates#
collapse.the.dates.new <- function(sites, region, context, dates, sigma, lat, long, datemin, datemax) {#
    n.t <- rep(100, length(sites))#
    df <- data.frame(sites, region, context, lat, long, as.numeric(dates), as.numeric(sigma))#
    colnames(df) <- c("Site", "Region", "Context", "Lat", "Long", "CYrBPunc", "Sigma")#
    df <- subset(df, df$CYrBPunc < datemax & df$CYrBPunc > datemin)#
    df <- arrange(df, desc(CYrBPunc))#
    df <- arrange(df, desc(Site))#
    df <- arrange(df, desc(Region))#
    df$Ttest <- c(#
    (abs(df[1:(nrow(df)-1),6]-df[2:nrow(df), 6]))/((sqrt(df[2:nrow(df), 7]^2 + df[1:(nrow(df)-1),7]^2)*sqrt(1/100))), NA)#
    df$pvalue <- c((2*pt(df[1:nrow(df),8], 100, lower=FALSE)))#
    df$Collapse <- rep("No", length(df$Site))#
    df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
    df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
    df <- as.data.frame(df)#
    df <- df[complete.cases(df),]#
    return(df)#
}#
neolithic.bio <- collapse.the.dates.begin(sites=neolithic.bio$Site, biogeo=neolithic.bio$Biogeo_Uni, general=neolithic.bio$St_Area_NE, dates=neolithic.bio$CYrBPunc, sigma=neolithic.bio$Sigma)#
#####Intersect 14C dates by region#
antonio.regions <- readOGR("/Users/lee/Dropbox/4.2 ky event/jwp paper/Event42_areasIberia", "Event42_areasIberia")#
antonio.p1 <- as(antonio.regions, "SpatialPolygons")#
antonio.p1@data$id = rownames(antonio.p1@data)#
#
small.frame <- data.frame(all.data$Region, all.data$Site, all.data$Site.Type, all.data$Site.Type.Simple, all.data$Context..phase..etc.., all.data$Lat.in.Dec, all.data$Long.in.Dec, all.data$Sample.Lab.Number, all.data$X14C.Yr.BP.uncal, all.data$Sigma)#
colnames(small.frame) <- c("Region", "Site", "Details", "Type", "Context", "Latitude", "Longitude", "LabNumber", "Date", "Sigma")#
small.frame <- small.frame[!(is.na(small.frame$Latitude) | small.frame$Latitude==""), ]#
small.frame <- small.frame[!(is.na(small.frame$Longitude) | small.frame$Longitude==""), ]#
small.frame$Region <- sub("^$", "0", small.frame$Region)#
small.frame$Site <- sub("^$", "0", small.frame$Site)#
small.frame$Type <- sub("^$", "0", small.frame$Type)#
small.frame$Context <- sub("^$", "0", small.frame$Context)#
small.frame$LabNumber <- sub("^$", "0", small.frame$LabNumber)#
small.frame$Date <- sub("^$", "0", small.frame$Date)#
small.frame$Sigma <- sub("^$", "0", small.frame$Sigma)#
iberia.points <- data.frame(small.frame)#
#
coordinates(iberia.points) = ~Longitude+Latitude#
proj4string(iberia.points) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0")#
#
iberia.points <- spTransform(iberia.points, CRS("+proj=utm +zone=30 +ellps=GRS80 +units=m +no_defs"))#
#
overlap <- over(iberia.points, antonio.regions)#
#
iberia.points@data$NewRegion <- overlap$Area_code#
iberia.point.var <- spTransform(iberia.points, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))#
iberia.data <- data.frame(iberia.points)#
iberia.data$Site <- as.character(iberia.data$Site)#
iberia.data2 <- data.frame(iberia.point.var)#
iberia.data2$NewRegion <- as.character(iberia.data2$NewRegion)#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SW", "Southwest")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="SE", "Southeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="Mediterranean", "Northeast")#
iberia.data2$NewRegion <- replace(iberia.data2$NewRegion, iberia.data2$NewRegion=="North", "Northwest")#
iberia.col <- collapse.the.dates.new(sites=iberia.data2$Site, region=iberia.data2$NewRegion, context=iberia.data2$Type, lat=iberia.data2$Latitude, long=iberia.data2$Longitude, dates=iberia.data2$Date, sigma=iberia.data2$Sigma, datemin=1000, datemax=14000)
##########################
###Generalized Regions####
##########################
#
northwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northwest")#
southwest.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southwest")#
southeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Southeast")#
meseta.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Meseta")#
northeast.14C <- subset(iberia.col$CYrBPunc, iberia.col$Region=="Northeast")#
northwest.sig<- subset(iberia.col$Sigma, iberia.col$Region=="Northwest")#
southwest.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southwest")#
southeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Southeast")#
meseta.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Meseta")#
northeast.sig <- subset(iberia.col$Sigma, iberia.col$Region=="Northeast")#
#
northwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northwest"))#
southwest.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southwest"))#
southeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Southeast"))#
meseta.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Meseta"))#
northeast.taxa <- as.vector(subset(iberia.col$Context, iberia.col$Region=="Northeast"))#
#
northwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northwest")#
southwest.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southwest")#
southeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Southeast")#
meseta.lat <- subset(iberia.col$Lat, iberia.col$Region=="Meseta")#
northeast.lat <- subset(iberia.col$Lat, iberia.col$Region=="Northeast")#
#
northwest.long <- subset(iberia.col$Long, iberia.col$Region=="Northwest")#
southwest.long <- subset(iberia.col$Long, iberia.col$Region=="Southwest")#
southeast.long <- subset(iberia.col$Long, iberia.col$Region=="Southeast")#
meseta.long <- subset(iberia.col$Long, iberia.col$Region=="Meseta")#
northeast.long <- subset(iberia.col$Long, iberia.col$Region=="Northeast")#
#
northwest.context <- subset(iberia.col$Context, iberia.col$Region=="Northwest")#
southwest.context <- subset(iberia.col$Context, iberia.col$Region=="Southwest")#
southeast.context <- subset(iberia.col$Context, iberia.col$Region=="Southeast")#
meseta.context <- subset(iberia.col$Context, iberia.col$Region=="Meseta")#
northeast.context <- subset(iberia.col$Context, iberia.col$Region=="Northeast")#
northwest.intcal <- rep("intcal13", length(northwest.14C))#
southwest.intcal <- rep("intcal13", length(southwest.14C))#
southeast.intcal <- rep("intcal13", length(southeast.14C))#
meseta.intcal <- rep("intcal13", length(meseta.14C))#
northeast.intcal <- rep("intcal13", length(northeast.14C))#
northwest.names <- rep("North", length(northwest.14C))#
southwest.names <- rep("Southwest", length(southwest.14C))#
southeast.names <- rep("Southeast", length(southeast.14C))#
meseta.names <- rep("Meseta", length(meseta.14C))#
northeast.names <- rep("Northeast", length(northeast.14C))#
northwest.sites<- subset(iberia.col$Site, iberia.col$Region=="Northwest")#
southwest.sites <- subset(iberia.col$Site, iberia.col$Region=="Southwest")#
southeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Southeast")#
meseta.sites <- subset(iberia.col$Site, iberia.col$Region=="Meseta")#
northeast.sites <- subset(iberia.col$Site, iberia.col$Region=="Northeast")#
northwest.site.count <- length(unique(as.vector(northwest.sites)))#
southwest.site.count <- length(unique(southwest.sites))#
southeast.site.count <- length(unique(southeast.sites))#
meseta.site.count <- length(unique(meseta.sites))#
northeast.site.count <- length(unique(northeast.sites))#
#
####################################################
#######Calibration & Confidence Band Function#######
####################################################
#
###Multicore apply function with status bar#
mcpblapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    if (!is.vector(X) || is.object(X))#
    X <- as.list(X)#
    B <- length(X)#
    if (!(interactive() && dopb() && B >= 1))#
    return(mclapply(X, FUN, ...#
    ))#
    pb <- startpb(0, B)#
    rval <- vector("list", B)#
    for (i in 1:B) {#
        rval[i] <- list(FUN(X[[i]], ...))#
        setpb(pb, i)#
    }#
    close(pb)#
    names(rval) <- names(X)#
    rval#
}#
#
mcpbsapply <- function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,#
mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),#
mc.cleanup = TRUE, mc.allow.recursive = TRUE, USE.NAMES = TRUE, simplify = TRUE)#
{#
    FUN <- match.fun(FUN)#
    answer <- mcpblapply(X = X, FUN = FUN,  ..., USE.NAMES = TRUE)#
    if (USE.NAMES && is.character(X) && is.null(names(answer)))#
    names(answer) <- X#
    if (!identical(simplify, FALSE) && length(answer))#
    simplify2array(answer, higher = (simplify == "array"))#
    else answer#
}#
#
mcreplicate <- function(n, expr, simplify = "array", mc.cores = getOption("mc.cores", 2L)) {#
#
mcpbsapply(integer(n), eval.parent(substitute(function(...) expr)), mc.cores = getOption("mc.cores", 2L),#
simplify = simplify)#
#
}#
conf.loess <- function(x, sigma, n, reps, xmin, xmax) { #
samp.intcal <- rep("intcal13", length(x))#
samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
samp.ages <- ldply(samp.slugdens, data.frame)#
res.by <- by(samp.ages$ageGrid, samp.ages$.id, median) #
res.t <- t(res.by)#
samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
time <- seq(xmin+5, xmax-5, 10)#
samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
samp.hist <- hist(samp.grid, breaks=length(time))#
samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
colnames(samp.hist) <- c("Age", "Counts", "Density")#
#samp.hist <- arrange(samp.all, desc(Age))#
#
makeloess <- function(x, n){#
time <- seq(xmin+5, xmax-5, 10)#
samp.age <- sample(x, size=n, replace=TRUE)#
samp.dist <- sapply(1:n, function(x) rnorm(500, samp.age, 85))#
samp.dist <- as.vector(samp.dist)#
samp.dist <- c(xmax, xmin, samp.dist)#
samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
samp.loess <- lowess(time, samp.date, f=0.15)#
samp.fitted <- samp.loess$y#
return(samp.fitted)#
}#
#
samp.replicate <- (replicate(reps, makeloess(res.t, n)))#
samp.replicate <- as.data.frame(samp.replicate)#
samp.replicate[is.na(samp.replicate)] <- 0#
samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
#
samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
#
samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
#samp.descriptive <- arrange(samp.descriptive, desc(Age))#
samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
names(samp.all)[names(samp.all)=="time"] <- "Age"#
names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
samp.all <- arrange(samp.all, desc(Age))#
return(samp.all)#
}#
#
d#
fmt <- function(){#
    function(x) format(x,nsmall = 4,scientific = FALSE)#
}#
###Traditional SCDPD#
BchronDensityCollapse <- function (dates, sigma, sites,  dfs = rep(100, length(dates)), numMix = 30,#
iterations = 10000, burn = 2000, thin = 8, updateAges = FALSE, collapse.dates=FALSE)#
{#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    pathToCalCurves = system.file("data",#
    package = "Bchron")#
    calCurves <- rep("intcal13", length(date.data$Date))#
    ages <- date.data$Date#
    ageSds <- date.data$Sigma#
    if (length(ages) != length(ageSds))#
    stop("ages and 1-sigma errors must be same length")#
    if (length(ages) != length(calCurves))#
    stop("ages and Calibration curves must be same length")#
    x = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, eps = 0, dfs = rep(100,#
    length(ages)))#
    xSmall = BchronCalibrate(ages = ages, ageSds = ageSds, calCurves = calCurves,#
    pathToCalCurves = pathToCalCurves, dfs = rep(100, length(ages)))#
    n = length(x)#
    thetaRange = range(xSmall[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, xSmall[[i]]$ageGrid))#
    offset = vector(length = n)#
    for (i in 1:n) {#
        offset[i] = ifelse(x[[i]]$calCurve == "normal", 61, 0)#
    }#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    clrInv = function(phi) {#
        return(exp(phi)/sum(exp(phi)))#
    }#
    J = numMix#
    mu = seq(thetaRange[1], thetaRange[2], length = numMix)#
    theta = vector(length = n)#
    for (j in 1:n) theta[j] = round(stats::rnorm(1, mean = x[[j]]$ageGrid[match(max(x[[j]]$densities),#
    x[[j]]$densities)], sd = ageSds[j]), 3)#
    phi = c(stats::runif(J - 1, -10, 10), 0)#
    p = as.numeric(clrInv(phi))#
    G = gbase(theta, mu)#
    remaining = (iterations - burn)/thin#
    thetaStore = matrix(ncol = length(theta), nrow = remaining)#
    pStore = matrix(ncol = J, nrow = remaining)#
    thetaAll = matrix(NA, ncol = n, nrow = iterations)#
    for (j in 1:n) thetaAll[, j] = sample(xSmall[[j]]$ageGrid,#
    size = iterations, prob = xSmall[[j]]$densities, replace = TRUE)#
    mu2 = mu#
    sigma2 = (mu[2] - mu[1])/2#
    my_dnorm = function(x) stats::dnorm(x, mean = mu2, sd = sigma2)#
    pb = utils::txtProgressBar(min = 1, max = iterations, style = 3,#
    width = 60, title = "Running BchronDensity")#
    for (i in 1:iterations) {#
        utils::setTxtProgressBar(pb, i)#
        if (i > burn & i%%thin == 0) {#
            ind = (i - burn)/thin#
            thetaStore[ind, ] = theta#
            pStore[ind, ] = p#
        }#
        if (updateAges) {#
            for (j in 1:n) {#
                thetaNew = round(stats::rnorm(1, theta[j], 0.5),#
                3)#
                thetaNewMatch = as.integer(thetaNew + offset[j]) +#
                1#
                thetaNewLogDens = max(log(x[[j]]$densities[thetaNewMatch]),#
                -1e+06)#
                priorNew.dens = sum(p * stats::dnorm(thetaNew,#
                mean = mu2, sd = sigma2))#
                thetaMatch = as.integer(theta[j] + offset[j]) +#
                1#
                thetaLogDens = max(log(x[[j]]$densities[thetaMatch]),#
                -1e+06)#
                priorDens = sum(p * stats::dnorm(theta[j], mean = mu2,#
                sd = sigma2))#
                logRtheta = thetaNewLogDens - thetaLogDens +#
                log(priorNew.dens) - log(priorDens)#
                if (stats::runif(1) < exp(logRtheta))#
                theta[j] = thetaNew#
            }#
        }#
        else {#
            theta = thetaAll[i, ]#
        }#
        for (j in 1:(J - 1)) {#
            phiNew = stats::rnorm(1, phi[j], 1)#
            phiAllNew = phi#
            phiAllNew[j] = phiNew#
            pNew = as.numeric(clrInv(phiAllNew))#
            phiNewLogDens = sum(log(G %*% pNew))#
            phiLogDens = sum(log(G %*% p))#
            logRphi = phiNewLogDens - phiLogDens + stats::dunif(phiNew,#
            -10, 10, log = TRUE) - stats::dunif(phi[j], -10,#
            10, log = TRUE)#
            if (stats::runif(1) < exp(logRphi)) {#
                phi[j] = phiNew#
                p = as.numeric(clrInv(phi))#
            }#
        }#
    }#
    output = list(theta = thetaStore, p = pStore, mu = mu, calAges = xSmall,#
    G = G)#
    class(output) = "BchronDensityRun"#
    return(output)#
}#
#
###Function to modify existing SCDPD from BchronDensity (modified from Bchron)#
SlugDens.t <- function (x, xmin, xmax)#
{#
    n = length(x$calAges)#
    thetaRange = range(x$calAges[[1]]$ageGrid)#
    for (i in 2:n) thetaRange = range(c(thetaRange, x$calAges[[i]]$ageGrid))#
    dateGrid = seq(xmin, xmax, length = 1000)#
    gauss <- function(x, mu, sig) {#
        u <- (x - mu)/sig#
        y <- exp(-u * u/2)#
        y#
    }#
    gbase <- function(x, mus) {#
        sig <- (mus[2] - mus[1])/2#
        G <- outer(x, mus, gauss, sig)#
        G#
    }#
    Gstar = gbase(dateGrid, x$mu)#
    dens = vector(length = length(dateGrid))#
    for (i in 1:nrow(x$p)) {#
        dens = dens + Gstar %*% x$p[i, ]#
    }#
    densFinal = dens/sum(dens)#
    slugbase <- data.frame(dateGrid,densFinal)#
    colnames(slugbase) <- c("Age", "Density")#
    slugbase <- arrange(slugbase, desc(Age))#
    return(slugbase)#
}#
#
SlugSig <- function(x, sigma, n, reps, xmin, xmax) {#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronDensity(x, sigma, samp.intcal, numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
    samp.hist <- SlugDens.t(samp.slugdens, xmin, xmax)#
    makeloess <- function(x, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.14C <- sample(x, size=n, replace=TRUE)#
        samp.sig <- sample(sigma, size=n, replace=TRUE)#
        samp.dist.n <- BchronDensity(samp.14C, samp.sig, rep("intcal13", n), numMix = 30, iterations=10000, burn=2000, thin=8, updateAges=FALSE)#
          samp.dist <- SlugDens.t(samp.dist.n, xmin, xmax)#
        samp.loess <- lowess(samp.dist$Age, samp.dist$Density, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(x, n)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(samp.hist$Age, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(samp.hist$Age, samp.hist$Density, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="samp.hist.Age"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
######Function to Generate Confidence Bands around SCDRD#
conf.cal.loess.old <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+1, xmax, 1)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.grid <- c(fill, samp.grid)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+1, xmax, 1)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(fill, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.cal.loess.trad <- function(dates, sigma, n, reps, sites, xmin, xmax, ..., cores = getOption("mc.cores", 2L), collapse.dates=FALSE) {#
    collapse.the.dates <- function(sites, dates, sigma) {#
        n.t <- rep(100, length(sites))#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        df <- arrange(df, desc(Date))#
        df <- arrange(df, desc(Sites))#
        df$Ttest <- c(#
        (abs(df[1:(nrow(df)-1),2]-df[2:nrow(df), 2]))/((sqrt(df[2:nrow(df), 3]^2 + df[1:(nrow(df)-1),3]^2)*sqrt(1/100))), NA)#
        df$pvalue <- c((2*pt(df[1:nrow(df),4], 100, lower=FALSE)))#
        df$Collapse <- rep("No", length(sites))#
        df <- transform(df, Collapse = ifelse(pvalue > 0.05, "Yes", Collapse))#
        df <- df[!(df$Collapse=="Yes" & df[1:(nrow(df)-1),1]==df[2:nrow(df), 1]),]#
        df <- as.data.frame(df)#
        df <- df[complete.cases(df),]#
        return(df)#
    }#
    uncollapse.the.dates <- function(sites, dates, sigma) {#
        df <- data.frame(sites, dates, sigma)#
        colnames(df) <- c("Sites", "Date", "Sigma")#
        return(df)#
    }#
    date.data <- if(isTRUE(collapse.dates)){#
        collapse.the.dates(sites, dates, sigma)#
    } else {#
        uncollapse.the.dates(sites, dates, sigma)#
    }#
    samp.intcal <- rep("intcal13", length(date.data$Date))#
    samp.slugdens <- BchronCalibrate(date.data$Date, date.data$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    res.by <- by(samp.ages$ageGrid, samp.ages$.id, median)#
    res.t <- t(res.by)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(dates, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        n.s <- length(dates)#
        samp.order <- sample(n.s, size=n, replace=TRUE)#
        samp.dist.n <- samp.slugdens[samp.order]#
        temp.ages <- ldply(samp.dist.n, data.frame)#
        temp.age.grid <- c(temp.ages$ageGrid, fill)#
        temp.grid <- temp.age.grid[temp.age.grid < xmax & samp.grid > xmin]#
        samp.dist <- c(fill, temp.grid)#
        samp.dist <- as.vector(samp.dist)#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
    }#
    samp.replicate <- (mcreplicate(reps, makeloess(dates, n)))#
    samp.replicate.dat <- as.data.frame(samp.replicate)#
    samp.replicate.dat[is.na(samp.replicate.dat)] <- 0#
    samp.replicated <- sweep(samp.replicate.dat,2,colSums(samp.replicate.dat),`/`)#
    samp.results.replicated.m <- transform(samp.replicated, MEAN=apply(X=samp.replicated, MARGIN=1, FUN=mean, na.rm = TRUE))#
    samp.results.replicated.s <- transform(samp.replicated, SD=apply(X=samp.replicated, MARGIN=1, FUN=sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicated.m$MEAN, samp.results.replicated.s$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
conf.loess <- function(dates, sigma, sites, n, reps, xmin, xmax) {#
    samp.intcal <- rep("intcal13", length(dates))#
    samp.slugdens <- BchronCalibrate(dates, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    small.age.frame <- data.frame(samp.ages$.id, as.vector(samp.ages$ageGrid), as.vector(samp.ages$ageSds))#
    colnames(small.age.frame) <- c("Id", "ageGrid", "ageSDS")#
    samp.test <- aggregate(small.age.frame[,2:3], by=list(small.age.frame$Id), FUN=median)#
    colnames(samp.test) <- c("Id", "Mean", "SD")#
    samp.test$Min <- samp.test$Mean-samp.test$SD#
    samp.test$Max <- samp.test$Mean+samp.test$SD#
    samp.age.grid <- c(samp.ages$ageGrid, xmin, xmax)#
    samp.age.grid <- subset(samp.age.grid, !(xmin > samp.age.grid | samp.age.grid > xmax))#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    samp.hist <- hist(c(samp.grid, xmin, xmax), breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    #samp.hist <- arrange(samp.all, desc(Age))#
    makeloess <- function(a.frame, n){#
        time <- seq(xmin+5, xmax-5, 10)#
        samp.id <- as.vector(sample(as.vector(a.frame$Id), size=n, replace=TRUE))#
        t.frame <- data.frame(t(a.frame))#
        colnames(t.frame) <- a.frame$Id#
        s.t.frame <- t.frame[,samp.id]#
        f.frame <- data.frame(t(s.t.frame))#
        #f.frame <- data.table(f.frame)#
        small.frame <- data.frame(f.frame$Id, f.frame$Min, f.frame$Max)#
        colnames(small.frame) <- c("Id", "Min", "Max")#
        small.list <- split(as.vector(small.frame[,2:3]), f=small.frame$Id)#
        small.list <- lapply(small.list, function(x) as.vector(x[1,]))#
        seq.gen <- function(a.frame) {#
            a.frame <- as.data.frame(a.frame)#
            at.vector <- as.numeric(as.vector(as.data.frame(t(a.frame))[,1]))#
            sequence <- seq(from=at.vector[1], to=at.vector[2], by=1)#
            return(sequence)#
        }#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- ldply(all.seq, data.frame)[,2]#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- as.vector(tapply(samp.dist, cut(samp.dist, length(time)), length))#
        all.seq <- lapply(small.list, function(x) seq.gen(x))#
        all.dates <- as.vector(ldply(all.seq, data.frame)[,2])#
        samp.dist <- subset(all.dates, !(xmin > all.dates | all.dates > xmax))#
        samp.dist <- c(xmax, xmin, samp.dist)#
        samp.date <- tapply(samp.dist, cut(samp.dist, length(time)), length)#
        samp.loess <- lowess(time, samp.date, f=0.15)#
        samp.fitted <- samp.loess$y#
        return(samp.fitted)#
#
    }#
    samp.replicate <- (pbreplicate(reps, makeloess(samp.test, reps)))#
    samp.replicate <- as.data.frame(samp.replicate)#
    samp.replicate[is.na(samp.replicate)] <- 0#
    samp.replicate <- sweep(samp.replicate,2,colSums(samp.replicate),`/`)#
    samp.results.replicate <- transform(samp.replicate, MEAN=apply(samp.replicate,1, mean, na.rm = TRUE))#
    samp.results.replicate <- transform(samp.results.replicate, SD=apply(samp.results.replicate,1, sd, na.rm = TRUE))#
    samp.descriptive <- data.frame(time, samp.results.replicate$MEAN, samp.results.replicate$SD)#
    colnames(samp.descriptive) <- c("Age", "Mean", "SD")#
    #samp.descriptive <- arrange(samp.descriptive, desc(Age))#
    samp.all <- data.frame(time, samp.hist$Density, samp.hist$Counts, samp.descriptive$Mean, samp.descriptive$SD, samp.replicate)#
    names(samp.all)[names(samp.all)=="time"] <- "Age"#
    names(samp.all)[names(samp.all)=="samp.descriptive.Mean"] <- "Mean"#
    names(samp.all)[names(samp.all)=="samp.descriptive.SD"] <- "SD"#
    names(samp.all)[names(samp.all)=="samp.hist.Density"] <- "Density"#
    names(samp.all)[names(samp.all)=="samp.hist.Counts"] <- "Counts"#
    samp.all <- arrange(samp.all, desc(Age))#
    return(samp.all)#
}#
stack.14C.taxa.old <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
stack.14C.taxa <- function(date, sigma, xmin, xmax, lat, long, taxa){#
    date <- c(date, 49000)#
    sigma <- c(sigma, 4900)#
    lat <- c(lat, 0)#
    long <- c(long, 0)#
    taxa <- c(taxa, "blank")#
    date.frame <- data.frame(date, sigma, lat, long, taxa)#
    names(date.frame) <- c("Date", "Sigma", "Lat", "Long", "Taxa")#
    date.frame <- date.frame[complete.cases(date.frame),]#
    date.sub <- subset(date.frame, (xmin-500) < Date & Date < (xmax + 500))#
    ids.cus = paste("date", 1:length(date.sub$Date), sep = "")#
    coord.sub <- data.frame(ids.cus, date.sub$Lat, date.sub$Long, date.sub$Taxa)#
    names(coord.sub) <- c(".id", "Lat", "Long", "Taxa")#
    samp.intcal <- rep("intcal13", length(date.sub$Date))#
    samp.slugdens <- BchronCalibrate(date.sub$Date, date.sub$Sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.mean <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, mean))#
    samp.sd <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, sd))#
    samp.frame <- data.frame(samp.mean, samp.sd)#
    colnames(samp.frame) <- c("Mean", "Sd")#
    samp.frame$Min <- samp.frame$Mean-date.sub$Sigma*2#
    samp.frame$Max <- samp.frame$Mean+date.sub$Sigma*2#
    samp.frame$Lat <- coord.sub$Lat#
    samp.frame$Long <- coord.sub$Long#
    samp.frame$Taxa <- coord.sub$Taxa#
    samp.frame <- data.table(samp.frame)#
    lat.frame <- samp.frame[, list(Lat=Lat, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    long.frame <- samp.frame[, list(Long=Long, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    taxa.frame <- samp.frame[, list(Taxa=Taxa, ageGrid = seq(from=trunc(Min), to=trunc(Max))), by = 1:nrow(samp.frame)]#
    fin.frame <- data.frame(taxa.frame$Taxa, lat.frame$Lat, long.frame$Long, lat.frame$ageGrid)#
    colnames(fin.frame) <- c("Taxa", "Lat", "Long", "ageGrid")#
    return(fin.frame)#
}#
#######
stack.14C <- function(x, sigma, xmin, xmax, taxa){#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(x, sigma, samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    fill <- seq(xmin, xmax, 1)#
    samp.age.grid <- c(samp.ages$ageGrid, fill)#
    samp.grid <- sort(samp.age.grid, decreasing=TRUE)#
    samp.grid <- samp.grid[samp.grid < xmax & samp.grid > xmin]#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist <- hist(samp.grid, breaks=length(time))#
    samp.hist <- data.frame(time, samp.hist$counts, samp.hist$counts/sum(samp.hist$counts))#
    colnames(samp.hist) <- c("Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
taphonomic.correct <- function(stack.14C.data) {#
    df <- stack.14C.data#
    n.t <- 5.726442*(10^6)*(df$Age + 2176.4)^-1.3925309#
    lambda <- 1.3925309/(2176.4+df$Age)*100#
    lambda.r <- 1-lambda#
    n.t.relative <- n.t/128.8192#
    df$Counts.Corrected <-df$Counts/n.t.relative#
    count.mod.sum <- sum(df$Counts.Corrected)#
    df$Density.Corrected <- df$Counts.Corrected/count.mod.sum#
    return(df)#
}#
criterion.data.null <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !stack.14C.taxa.object$Taxa==criteria.names)#
    ageGrids <- c(temp.df.1$ageGrid, temp.df.2$ageGrid)#
    Taxa <- c(as.vector(temp.df.1$Taxa), rep("Other", length(temp.df.2$ageGrid)))#
    temp.df <- data.frame(ageGrids, Taxa)#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    return(corrected.samp.hist)#
}#
criterion.data.old <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    samp.hist <- data.frame(samp.mids.df[1], samp.mids.df[2], samp.counts.df[2], samp.density.df[2])#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, corrected.samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)), even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    colnames(temp.df) <- c("ageGrid", "Taxa")#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    colnames(temp.df.alt) <- c("ageGrid", "Taxa")#
    temp.list <- split(temp.df$ageGrid, f=temp.df$Taxa)#
    temp.list <- rapply(temp.list, f=sort, how="list", decreasing=TRUE)#
    time <- seq(xmin+5, xmax-5, 10)#
    samp.hist.list <- rapply(temp.list, f=hist, how="list", breaks=length(time))#
    samp.mids <- sapply(samp.hist.list, "[[", 4)#
    samp.counts <- sapply(samp.hist.list, "[[", 2)#
    samp.density <- sapply(samp.hist.list, "[[", 3)#
    samp.mids.df <- ldply(samp.mids, data.frame)#
    samp.counts.df <- ldply(samp.counts, data.frame)#
    samp.density.df <- ldply(samp.density, data.frame)#
    temp.list.alt <- split(temp.df.alt$ageGrid, f=temp.df.alt$Taxa)#
    temp.list.alt <- rapply(temp.list.alt, f=sort, how="list", decreasing=TRUE)#
    samp.hist.list.alt <- rapply(temp.list.alt, f=hist, how="list", breaks=length(time))#
    samp.mids.alt <- sapply(samp.hist.list.alt, "[[", 4)#
    samp.counts.alt <- sapply(samp.hist.list.alt, "[[", 2)#
    samp.density.alt <- sapply(samp.hist.list.alt, "[[", 3)#
    samp.mids.df.alt <- ldply(samp.mids.alt, data.frame)#
    samp.counts.df.alt <- ldply(samp.counts.alt, data.frame)#
    samp.density.df.alt <- ldply(samp.density.alt, data.frame)#
    hist.alt <- hist(temp.df.alt$ageGrid, breaks=length(time))#
    samp.mids.alt <- hist.alt$mids#
    samp.counts.alt <- hist.alt$counts#
    count.sum <- sum(samp.counts.alt)#
    samp.density.alt <- hist.alt$density#
    samp.names.alt <- rep("Total", length(samp.mids.alt))#
    samp.hist <- data.frame(c(samp.mids.df[,1], samp.names.alt), as.numeric(as.vector(c(samp.mids.df[,2], samp.mids.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt))), as.numeric(as.vector(c(samp.counts.df[,2], samp.counts.alt)))/count.sum)#
    colnames(samp.hist) <- c("Taxa", "Age", "Counts", "Density")#
    corrected.samp.hist <- taphonomic.correct(samp.hist)#
    even.more.corrected.samp.hist <- as.data.frame(xtabs(Counts~Age+Taxa, samp.hist))#
    final.samp.hist <- data.frame(abs(1950-as.numeric(as.vector(even.more.corrected.samp.hist$Age))), as.numeric(as.vector(even.more.corrected.samp.hist$Freq)),#
        as.numeric(as.vector(even.more.corrected.samp.hist$Freq))/count.sum,#
        even.more.corrected.samp.hist$Taxa)#
    colnames(final.samp.hist) <- c("Age", "Counts", "Density", "Taxa")#
    return(final.samp.hist)#
}#
criterion.data.test <- function(stack.14C.taxa.object, criteria.names, xmin, xmax) {#
    temp.df.1 <- subset(stack.14C.taxa.object, stack.14C.taxa.object$Taxa==criteria.names)#
    temp.df.2 <- subset(stack.14C.taxa.object, !(stack.14C.taxa.object$Taxa==criteria.names))#
    temp.df <- data.frame(temp.df.1$ageGrid, as.vector(temp.df.1$Taxa))#
    temp.df.alt <- data.frame(temp.df.2$ageGrid, rep("Total", length(temp.df.2$ageGrid)))#
    df <- data.frame(c(temp.df.1$ageGrid, temp.df.2$ageGrid), c(as.vector(temp.df.1$Taxa), rep("Total", length(temp.df.2$ageGrid))))#
    colnames(df) <- c("ageGrid", "Taxa")#
    return(df)#
}#
median.stack.14C.half <- function(x, sigma, sites, context, xmin, xmax){#
      intcal13 <- intcal.13#
    samp.intcal <- rep("intcal13", length(x))#
    samp.slugdens <- BchronCalibrate(as.numeric(as.vector(x)), as.numeric(as.vector(sigma)), samp.intcal)#
    samp.ages <- ldply(samp.slugdens, data.frame)#
    samp.median <- data.frame(tapply(samp.ages$ageGrid, samp.ages$.id, median))#
    medians.all <-as.vector(samp.median[,1])#
    small.frame <- data.frame(medians.all, sites, context)#
    colnames(small.frame) <- c("Median", "Site", "Context")#
    #medians <- medians.all[medians.all < xmax & medians.all > xmin]#
    small.frame <- subset(small.frame, !(small.frame$Median > xmax | small.frame$Median < xmin))#
    return(small.frame)#
}
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
intcal.13 <- read.csv(file="http://www.bleedrake.com/Neolithic/intcal13.csv")
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
table(southeast.med$Context)
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=3300, xmin=1500)
table(southeast.med$Context)
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
write.table(southeast.med, file="~/southeastmed.csv", sep=",")
chaco.light.quant <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco Geochem/Chaco Arroyo Z Light/Arroyo Z Light Cal-Table 1.csv")
fe.plot <- ggplot(chaco.light.quant, aes(Ti, Fe)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Ti (%)") +#
scale_y_continuous("Fe (%)") +#
theme_bw()
fe.plot
lm_eqn = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(C)[i] == a + b %.% italic(I)[i]*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}#
#
lm_eqn_val = function(m) {#
    l <- list(a = format(coef(m)[1], digits = 2),#
    b = format(abs(coef(m)[2]), digits = 2),#
    r2 = format(summary(m)$r.squared, digits = 3));#
        eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)#
    as.character(as.expression(eq));#
}
fe.plot <- ggplot(chaco.light.quant, aes(Ti, Fe)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Ti (%)") +#
scale_y_continuous("Fe (%)") +#
annotate("text", label=lm_eqn_val(lm(Fe~Ti, chaco.light.quant)), x=1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_bw()
fe.plot
fe.plot <- ggplot(chaco.light.quant, aes(Ti, Fe)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Ti (%)") +#
scale_y_continuous("Fe (%)") +#
annotate("text", label=lm_eqn_val(lm(Fe~Ti, chaco.light.quant)), x=0.05, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_bw()
fe.plot
fe.plot <- ggplot(chaco.light.quant, aes(Ti, Fe)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Ti (%)") +#
scale_y_continuous("Fe (%)") +#
annotate("text", label=lm_eqn_val(lm(Fe~Ti, chaco.light.quant)), x=0.1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_bw()
fe.plot
al.k.plot <- ggplot(chaco.light.quant, aes(Al, K)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Al (%)") +#
scale_y_continuous("K (%)") +#
annotate("text", label=lm_eqn_val(lm(Al~K, chaco.light.quant)), x=0.1, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_bw()
al.k.plot
al.k.plot <- ggplot(chaco.light.quant, aes(Al, K)) +#
geom_point() +#
stat_smooth(method="lm") +#
scale_x_continuous("Al (%)") +#
scale_y_continuous("K (%)") +#
annotate("text", label=lm_eqn_val(lm(Al~K, chaco.light.quant)), x=2.75, y=Inf, hjust=0, vjust=1, parse=TRUE)+#
theme_bw()
al.k.plot
northwest.med <- median.stack.14C.half(x=northwest.14C, sigma=northwest.sig, context=northwest.context, sites=northwest.sites, xmax=5500, xmin=500)#
meseta.med <- median.stack.14C.half(x=meseta.14C, sigma=meseta.sig, context=meseta.context, sites=meseta.sites, xmax=5500, xmin=500)#
northeast.med <- median.stack.14C.half(x=northeast.14C, sigma=northeast.sig, context=northeast.context, sites=northeast.sites, xmax=5500, xmin=500)#
southwest.med <- median.stack.14C.half(x=southwest.14C, sigma=southwest.sig, context=southwest.context, sites=southwest.sites, xmax=5500, xmin=500)#
southeast.med <- median.stack.14C.half(x=southeast.14C, sigma=southeast.sig, context=southeast.context, sites=southeast.sites, xmax=5500, xmin=500)
library(xlsx)
write.xlsx(northwest.med, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/auditeddates.xlsx", sheetName="Northwest")#
write.xlsx(meseta.med, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/auditeddates.xlsx", sheetName="Meseta", append=TRUE)#
write.xlsx(northeast.med, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/auditeddates.xlsx", sheetName="Northeast", append=TRUE)#
write.xlsx(southwest.med, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/auditeddates.xlsx", sheetName="Southwest", append=TRUE)#
write.xlsx(southeast.med, file="/Users/lee/Dropbox/4.2 ky event/jwp paper/SCDRD/auditeddates.xlsx", sheetName="Southeast", append=TRUE)
library(rgl)
bg3d("white") # if you want a black background#
rgl.spheres(0, 0, 0, texture="~/Dropbox/Documents/Anacom/Maps/Raw/Silicon.png", lit=FALSE)
bg3d("white") # if you want a black background#
rgl.spheres(0, 0, 0, texture="~/Dropbox/Documents/Anacom/Maps/Raw/Phosphorous.png", lit=FALSE)
library(ggplot2)#
library(gridExtra)#
library(dplR)#
library(pbapply)#
library(reshape)#
library(reshape2)#
library(Biobase)#
library(xlsx)#
library(forecast)#
library(ggmap)#
library(plyr)#
library(akima)#
#####Functions#
####Function to organize plots in a window#
layOut = function(...) {#
    require(grid)#
    x <- list(...)#
    n <- max(sapply(x, function(x) max(x[[2]])))#
    p <- max(sapply(x, function(x) max(x[[3]])))#
    pushViewport(viewport(layout = grid.layout(n, p)))#
    for (i in seq_len(length(x))) {#
        print(x[[i]][[1]], vp = viewport(layout.pos.row = x[[i]][[2]],#
        layout.pos.col = x[[i]][[3]]))#
    }#
}#
lm.dat <- function (formula, data, subset, weights, na.action, method = "qr",#
model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,#
contrasts = NULL, offset, ...)#
{#
    dat.fram <- data.frame(x, y)#
    dat.fram <- dat.fram[complete.cases(dat.fram),]#
    x <- dat.fram$x#
    y <- dat.fram$y#
    ret.x <- x#
    ret.y <- y#
    cl <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
    m <- match(c("formula", "data", "subset", "weights", "na.action",#
    "offset"), names(mf), 0L)#
    mf <- mf[c(1L, m)]#
    mf$drop.unused.levels <- TRUE#
    mf[[1L]] <- quote(stats::model.frame)#
    mf <- eval(mf, parent.frame())#
    if (method == "model.frame")#
    return(mf)#
    else if (method != "qr")#
    warning(gettextf("method = '%s' is not supported. Using 'qr'",#
    method), domain = NA)#
    mt <- attr(mf, "terms")#
    y <- model.response(mf, "numeric")#
    w <- as.vector(model.weights(mf))#
    if (!is.null(w) && !is.numeric(w))#
    stop("'weights' must be a numeric vector")#
    offset <- as.vector(model.offset(mf))#
    if (!is.null(offset)) {#
        if (length(offset) != NROW(y))#
        stop(gettextf("number of offsets is %d, should equal %d (number of observations)",#
        length(offset), NROW(y)), domain = NA)#
    }#
    if (is.empty.model(mt)) {#
        x <- NULL#
        z <- list(coefficients = if (is.matrix(y)) matrix(, 0,#
        3) else numeric(), residuals = y, fitted.values = 0 *#
        y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w !=#
        0) else if (is.matrix(y)) nrow(y) else length(y))#
        if (!is.null(offset)) {#
            z$fitted.values <- offset#
            z$residuals <- y - offset#
        }#
    }#
    else {#
        x <- model.matrix(mt, mf, contrasts)#
        z <- if (is.null(w))#
        lm.fit(x, y, offset = offset, singular.ok = singular.ok,#
        ...)#
        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok,#
        ...)#
    }#
    class(z) <- c(if (is.matrix(y)) "mlm", "lm")#
    z$na.action <- attr(mf, "na.action")#
    z$offset <- offset#
    z$contrasts <- attr(x, "contrasts")#
    z$xlevels <- .getXlevels(mt, mf)#
    z$call <- cl#
    z$terms <- mt#
    if (model)#
    z$model <- mf#
    if (ret.x)#
    z$x <- x#
    if (ret.y)#
    z$y <- y#
    if (!qr)#
    z$qr <- NULL#
    z#
}#
#
unlist.tree <- function(temp, myfiles){#
    n <- length(temp)#
    for (i in n) {#
        temp[i] <- myfiles[[i]]#
    }#
}#
#
ig.na <- function(x) {#
    length(na.omit(x))#
}#
#
nonNAs <- function(x) {#
    n <- as.vector(apply(x, 1, function(x) length(which(!is.na(x)))))#
    return(n)#
}#
#
readRWL.simp <- function(file) {#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    non.total <- data.frame(years, raw)#
    colnames(non.total)[1] <- "Year"#
    return(non.total)#
}#
#
readRWLArima <- function(file) {#
    raw <- read.rwl(file)#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    detrended <- data.frame(detrend(raw, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="residuals"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
#
readDataArima <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    arima.data <- pbapply(X=detrended, MARGIN=2, function(x) FUN=auto.arima(x)$residuals)#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArimaFit <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, function(x) FUN=fitted(auto.arima(x)))#
    arima.total <- data.frame(years, list.arima)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArima4 <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline"))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="x"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
meanSequence <- function(tree.dataframe, name) {#
    n <- length(tree.dataframe)#
    sequ <- rowMeans(tree.dataframe[2:n], na.rm=TRUE)#
    results.frame <- data.frame(as.numeric(as.vector(tree.dataframe$Year)), sequ)#
    colnames(results.frame) <- c("Year", name)#
    return(results.frame)#
}#
#
treeHypothesis <- function(time, tree.dataframe.1, tree.dataframe.2) {#
    tree.a <- tree.dataframe.1[match(time, tree.dataframe.1$Year, nomatch=0),]#
    tree.b <- tree.dataframe.2[match(time, tree.dataframe.2$Year, nomatch=0),]#
    df <- data.frame(time, tree.a$Mean, tree.b$Mean, tree.a$SD, tree.b$SD, tree.a$N, tree.b$N)#
    colnames(df) <- c("Year", "FirstMean", "SecondMean", "FirstSD", "SecondSD", "FirstN", "SecondN")#
    df$Ttest <- c(abs(df$FirstMean-df$SecondMean)/(sqrt((df$FirstSD^2)/df$FirstN + (df$SecondSD^2)/df$SecondN)))#
    df$DF <- c(((((df$FirstSD^2)/df$FirstN) +  ((df$SecondSD^2)/df$SecondN))^2)/((df$FirstSD^4)/((df$FirstN^2)*(df$FirstN-1)) + (df$SecondSD^4)/((df$SecondN^2)*(df$SecondN-1))))#
    df$pvalue <- c((2*pt(df$Ttest, df$DF, lower=FALSE)))#
    df$Significant <- rep("Yes", length(df$Year))#
    df <- transform(df, Significant = ifelse(pvalue > 0.05, "No", Significant))#
    return(df)#
}#
#
sigCount <- function(tree.hypothesis.test.results) {#
    Yes <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="Yes")#
    No <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="No")#
    Yess <- length(Yes)#
    Nos <- length(No)#
    results <- data.frame(mean(Yes), mean(No), Yess, Nos)#
    colnames(results) <- c("p-value diff", "p-value same", "p < 0.05", "p > 0.05")#
    return(results)#
}#
treeCorTest <- function(time, tree.object, tree.source){#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- data.frame(tree.b$Year, tree.b[,2])#
    colnames(tree.b.frame) <- c("Year", "B")#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- tree.b.frame$B[tree.b.frame$Year %in% tree.a$Year]#
    trees.grid <- data.frame(tree.a.re, tree.b.re)#
    colnames(trees.grid) <- c("First", "Second")#
    trees.lm <- lm(trees.grid$First~trees.grid$Second)#
    trees.s.lm <- summary(trees.lm)#
    turn.to.t <- function(x.lm) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- turn.to.t(trees.lm)#
    result.frame <- data.frame(trees.t,sqrt(trees.s.lm$r.squared), length(trees.lm$residuals))#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(result.frame)#
}#
treeCorTestMultiple <- function(time, tree.object, tree.sources){#
    tree.sources.n <- length(tree.sources)#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.sources[match(time, tree.sources$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- tree.b#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- semi_join(tree.b.frame, tree.a.frame, by="Year")#
    tree.sources.frame <- tree.b.re[2:tree.sources.n]#
    colnames(tree.sources.frame) <- names(tree.sources[2:tree.sources.n])#
    tree.total.frame <- data.frame(tree.a.re, tree.sources.frame)#
    colnames(tree.total.frame) <- c("to.test", names(tree.sources.frame))#
    trees.r2 <- apply(tree.sources.frame, 2, function(x) summary(lm(x~tree.a.re))$r.squared)#
    trees.n <- apply(tree.sources.frame, 2, function(x) length(summary(lm(x~tree.a.re))$residuals))#
    turn.to.t <- function(trees.rsquared, trees.residual.n) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- sqrt(trees.r2)*sqrt(trees.n-2)/sqrt(1-trees.r2)#
    trees.r <- sqrt(trees.r2)#
    result.frame <- data.frame(trees.t, trees.r, trees.n)#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnife <- function(time,  tree.dataframe, tree.source) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re <- tree.a.mod[tree.a.mod$Year %in% tree.b$Year, ]#
    tree.b.re <- tree.b[tree.b$Year %in% tree.a.mod$Year, ]#
    tree.a.re.re <- tree.a.re[2:samp.n]#
    source <- tree.b.re[,2]#
    n <- length(ls(tree.a.re))#
    group.lm.r2 <- apply(tree.a.re.re, 2, function(x) as.vector(summary(lm(x~source))$r.squared))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.lm.res.n <- apply(tree.a.re.re, 2, function(x) as.numeric(length(summary(lm(x~source))$residuals)))#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnifeAlt <- function(time,  tree.dataframe) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re.re <- tree.a.mod[2:samp.n]#
    n <- length(tree.a.re.re)#
    group.lm.r2 <- do.call("rbind", sapply(1:n, FUN = function(i) summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$r.squared, simplify=FALSE))#
    group.lm.res.n <- do.call("rbind", sapply(1:n, FUN = function(i) length(summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$residuals), simplify=FALSE))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
#
treeJackKnifeMultiple <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- data.frame(subListExtract(L=all.group.t, name="t-value"))#
    colnames(t.value) <- source.names#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSig <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.names <- names(tree.dataframe)#
    tree.names <- tree.names[2:length(tree.names)]#
    cat(gettext(tree.names))#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
#
t.value$Difference <- rep("Yes", length(t.value$Mean))#
t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
t.value.names <- names(t.value)#
#t.value <- data.frame(tree.names, t.value)#
#colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSigSamp <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.n <- length(tree.dataframe)#
    tree.names <- names(tree.dataframe[2:tree.n])#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
    t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    t.value <- data.frame(tree.names, t.value)#
    colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
#
percent <- function(x, digits = 2, format = "f", ...) {#
    paste0(formatC(100 * x, format = format, digits = digits, ...), "%")#
}#
#
populationSig <- function(x) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes"))#
    No <- length(subset(x$pvalue, x$Difference=="No"))#
    Ratio <- Yes/(sum(Yes, No))#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
}#
#
populationSigDefinition <- function(x, source.hypothesis) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes" & x$Source == source.hypothesis))#
    No <- length(x$pvalue)-Yes#
    Ratio <- Yes/length(x$pvalue)#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
#
}#
#
populationSigDefinitionMultiple <- function(x, source.hypotheses) {#
    hold <- rep(0, length(source.hypotheses))#
    hold.frame <- data.frame(t(hold))#
    colnames(hold.frame) <- source.hypotheses#
    n <- length(x$Difference)#
    x.subset <- subset(x, x$Difference=="Yes")#
    x.source <- table(x.subset$Source)#
    x.values <- as.numeric(paste(x.source))#
    x.frame <- data.frame(t(x.values))#
    colnames(x.frame) <- names(x.source)#
    Yes <- length(subset(x$Source, x$Difference=="Yes"))#
    None.n <- length(subset(x$Source, x$Difference=="No"))#
    None <- None.n/n#
    Ratio <- Yes/(Yes+None.n)#
    results.frame <- merge(hold.frame, x.frame, all=TRUE)#
    results.frame[is.na(results.frame)] <- 0#
    result.frame <- data.frame(results.frame[2,]/n, None, Ratio)#
    return(format(result.frame, digits=2))#
}#
#
multiplePopulationSig <- function(t.table.list) {#
         yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
         return(yes.no.table)#
     }#
#
test.list <- list(Chuska.JackKnife.t,Crystal.JackKnife.t)#
multiplePopulationSig(test.list)#
multiplePopulationSig <- function(x,...) {#
    yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
    return(yes.no.table)#
}#
#
treeBayes <- function () {#
    ####Prior Probability#
    prior.prob <- 1/length(source.names)#
    prior.opp <- 1-prior#
    ###Source Probability#
    source.prob <-#
    source.opp <-#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    prior <- 1/length(source.names)#
    prior.opp <- 1-prior#
    new <- 1-t.value$pvalue#
    opp <- t.value$pvalue#
    true.positive <- prior*new#
    false.positive <- prior.opp*opp#
    false.negative <- prior.opp*new#
    true.negative <- prior#
    t.value$Posterior <-#
}#
#
sourceGrid <- function(fileDirectory, sourceDefinitions, time, source.hypotheses) {#
    setwd(fileDirectory)#
    temp <- list.files(pattern="*.txt")#
    myRWL <- pblapply(temp, readRWLArima)#
    myJackKnife <- lapply(myRWL,  function(x) treeJackKnifeMultipleSourceSig(time, x, source.list, return="t-value"))#
    mySigDef <- lapply(myJackKnife, function(x) populationSigDefinitionMultiple(x, source.hypotheses))#
    myResults <- ldply (mySigDef, data.frame)#
    rownames(myResults) <- gsub(".txt", "", temp, )#
    return(myResults)#
}#
################
###Load Data####
################
####Define Time#
time <- seq(1600, 1900, 1)#
#
all <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco/All Guitermann Data.csv")#
#
CHU <- data.frame(all$Year, auto.arima(all$CHU)$residuals)#
colnames(CHU) <- c("Year", "CHU")#
#
CEB <- data.frame(all$Year, auto.arima(all$CEB)$residuals)#
colnames(CEB) <- c("Year", "CEB")#
#
CIB <- data.frame(all$Year, auto.arima(all$CIB)$residuals)#
colnames(CIB) <- c("Year", "CIB")#
#
GOB <- data.frame(all$Year, auto.arima(all$GOB)$residuals)#
colnames(GOB) <- c("Year", "GOB")#
#
JEM <- data.frame(all$Year, auto.arima(all$JEM)$residuals)#
colnames(JEM) <- c("Year", "JEM")#
#
MEA <- data.frame(all$Year, auto.arima(all$MEA)$residuals)#
colnames(MEA) <- c("Year", "MEA")#
#
MVER <- data.frame(all$Year, auto.arima(all$MVER)$residuals)#
colnames(MVER) <- c("Year", "MVER")#
#
DUR <- data.frame(all$Year, auto.arima(all$DUR)$residuals)#
colnames(DUR) <- c("Year", "DUR")#
#
source.hypotheses <- c("CHU","CEB","CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
all.sources <- data.frame(all$Year, all$CHU, all$CEB, all$CIB, all$GOB, all$JEM, all$MEA, all$MVER,  all$DUR)#
colnames(all.sources) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
###Copy and paste this script into the R console on your computer. It will be compatible with Windows, Mac, and Linux.#
#
###All sentences beginning with "###" will be invisible to the software, and will caption and describe each step of the analysis and figures for [CITATION]#
#
###Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
###Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###IMPORTANT NOTE: R uses packages to facilitate the analysis of data and production of figures. If you do not have the TTR, bcp, or ggplot2 packages installed, the following three lines of text will do it for you - all you have to do is delete the "###" that precedes the commands#
#
###The command below will bring up a list of download sites. Pick one closest to you to speed up the download process#
###chooseCRANmirror()#
#
###The script below will then install the TTR package (for moving averages), bcp package (for Bayesian Change-Point analysis), and ggplot2 (for generating data plots)#
###Note: Installation of packages may take up to an hour, depending upon the speed of your internect connection. #
###install.packages("TTR", dependencies = TRUE)#
###install.packages("bcp", dependencies = TRUE)#
###install.packages("ggplot2", dependencies = TRUE)#
#
###Activate the packages#
#
library(ggplot2)#
library(gridExtra)#
library(dplR)#
library(pbapply)#
library(reshape)#
library(reshape2)#
library(Biobase)#
library(xlsx)#
library(forecast)#
library(ggmap)#
library(plyr)#
library(akima)#
#####Functions#
####Function to organize plots in a window#
layOut = function(...) {#
    require(grid)#
    x <- list(...)#
    n <- max(sapply(x, function(x) max(x[[2]])))#
    p <- max(sapply(x, function(x) max(x[[3]])))#
    pushViewport(viewport(layout = grid.layout(n, p)))#
    for (i in seq_len(length(x))) {#
        print(x[[i]][[1]], vp = viewport(layout.pos.row = x[[i]][[2]],#
        layout.pos.col = x[[i]][[3]]))#
    }#
}#
lm.dat <- function (formula, data, subset, weights, na.action, method = "qr",#
model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,#
contrasts = NULL, offset, ...)#
{#
    dat.fram <- data.frame(x, y)#
    dat.fram <- dat.fram[complete.cases(dat.fram),]#
    x <- dat.fram$x#
    y <- dat.fram$y#
    ret.x <- x#
    ret.y <- y#
    cl <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
    m <- match(c("formula", "data", "subset", "weights", "na.action",#
    "offset"), names(mf), 0L)#
    mf <- mf[c(1L, m)]#
    mf$drop.unused.levels <- TRUE#
    mf[[1L]] <- quote(stats::model.frame)#
    mf <- eval(mf, parent.frame())#
    if (method == "model.frame")#
    return(mf)#
    else if (method != "qr")#
    warning(gettextf("method = '%s' is not supported. Using 'qr'",#
    method), domain = NA)#
    mt <- attr(mf, "terms")#
    y <- model.response(mf, "numeric")#
    w <- as.vector(model.weights(mf))#
    if (!is.null(w) && !is.numeric(w))#
    stop("'weights' must be a numeric vector")#
    offset <- as.vector(model.offset(mf))#
    if (!is.null(offset)) {#
        if (length(offset) != NROW(y))#
        stop(gettextf("number of offsets is %d, should equal %d (number of observations)",#
        length(offset), NROW(y)), domain = NA)#
    }#
    if (is.empty.model(mt)) {#
        x <- NULL#
        z <- list(coefficients = if (is.matrix(y)) matrix(, 0,#
        3) else numeric(), residuals = y, fitted.values = 0 *#
        y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w !=#
        0) else if (is.matrix(y)) nrow(y) else length(y))#
        if (!is.null(offset)) {#
            z$fitted.values <- offset#
            z$residuals <- y - offset#
        }#
    }#
    else {#
        x <- model.matrix(mt, mf, contrasts)#
        z <- if (is.null(w))#
        lm.fit(x, y, offset = offset, singular.ok = singular.ok,#
        ...)#
        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok,#
        ...)#
    }#
    class(z) <- c(if (is.matrix(y)) "mlm", "lm")#
    z$na.action <- attr(mf, "na.action")#
    z$offset <- offset#
    z$contrasts <- attr(x, "contrasts")#
    z$xlevels <- .getXlevels(mt, mf)#
    z$call <- cl#
    z$terms <- mt#
    if (model)#
    z$model <- mf#
    if (ret.x)#
    z$x <- x#
    if (ret.y)#
    z$y <- y#
    if (!qr)#
    z$qr <- NULL#
    z#
}#
#
unlist.tree <- function(temp, myfiles){#
    n <- length(temp)#
    for (i in n) {#
        temp[i] <- myfiles[[i]]#
    }#
}#
#
ig.na <- function(x) {#
    length(na.omit(x))#
}#
#
nonNAs <- function(x) {#
    n <- as.vector(apply(x, 1, function(x) length(which(!is.na(x)))))#
    return(n)#
}#
#
readRWL.simp <- function(file) {#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    non.total <- data.frame(years, raw)#
    colnames(non.total)[1] <- "Year"#
    return(non.total)#
}#
#
readRWLArima <- function(file) {#
    raw <- read.rwl(file)#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    detrended <- data.frame(detrend(raw, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="residuals"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
#
readDataArima <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    arima.data <- pbapply(X=detrended, MARGIN=2, function(x) FUN=auto.arima(x)$residuals)#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArimaFit <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, function(x) FUN=fitted(auto.arima(x)))#
    arima.total <- data.frame(years, list.arima)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArima4 <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline"))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="x"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
meanSequence <- function(tree.dataframe, name) {#
    n <- length(tree.dataframe)#
    sequ <- rowMeans(tree.dataframe[2:n], na.rm=TRUE)#
    results.frame <- data.frame(as.numeric(as.vector(tree.dataframe$Year)), sequ)#
    colnames(results.frame) <- c("Year", name)#
    return(results.frame)#
}#
#
treeHypothesis <- function(time, tree.dataframe.1, tree.dataframe.2) {#
    tree.a <- tree.dataframe.1[match(time, tree.dataframe.1$Year, nomatch=0),]#
    tree.b <- tree.dataframe.2[match(time, tree.dataframe.2$Year, nomatch=0),]#
    df <- data.frame(time, tree.a$Mean, tree.b$Mean, tree.a$SD, tree.b$SD, tree.a$N, tree.b$N)#
    colnames(df) <- c("Year", "FirstMean", "SecondMean", "FirstSD", "SecondSD", "FirstN", "SecondN")#
    df$Ttest <- c(abs(df$FirstMean-df$SecondMean)/(sqrt((df$FirstSD^2)/df$FirstN + (df$SecondSD^2)/df$SecondN)))#
    df$DF <- c(((((df$FirstSD^2)/df$FirstN) +  ((df$SecondSD^2)/df$SecondN))^2)/((df$FirstSD^4)/((df$FirstN^2)*(df$FirstN-1)) + (df$SecondSD^4)/((df$SecondN^2)*(df$SecondN-1))))#
    df$pvalue <- c((2*pt(df$Ttest, df$DF, lower=FALSE)))#
    df$Significant <- rep("Yes", length(df$Year))#
    df <- transform(df, Significant = ifelse(pvalue > 0.05, "No", Significant))#
    return(df)#
}#
#
sigCount <- function(tree.hypothesis.test.results) {#
    Yes <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="Yes")#
    No <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="No")#
    Yess <- length(Yes)#
    Nos <- length(No)#
    results <- data.frame(mean(Yes), mean(No), Yess, Nos)#
    colnames(results) <- c("p-value diff", "p-value same", "p < 0.05", "p > 0.05")#
    return(results)#
}#
treeCorTest <- function(time, tree.object, tree.source){#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- data.frame(tree.b$Year, tree.b[,2])#
    colnames(tree.b.frame) <- c("Year", "B")#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- tree.b.frame$B[tree.b.frame$Year %in% tree.a$Year]#
    trees.grid <- data.frame(tree.a.re, tree.b.re)#
    colnames(trees.grid) <- c("First", "Second")#
    trees.lm <- lm(trees.grid$First~trees.grid$Second)#
    trees.s.lm <- summary(trees.lm)#
    turn.to.t <- function(x.lm) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- turn.to.t(trees.lm)#
    result.frame <- data.frame(trees.t,sqrt(trees.s.lm$r.squared), length(trees.lm$residuals))#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(result.frame)#
}#
treeCorTestMultiple <- function(time, tree.object, tree.sources){#
    tree.sources.n <- length(tree.sources)#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.sources[match(time, tree.sources$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- tree.b#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- semi_join(tree.b.frame, tree.a.frame, by="Year")#
    tree.sources.frame <- tree.b.re[2:tree.sources.n]#
    colnames(tree.sources.frame) <- names(tree.sources[2:tree.sources.n])#
    tree.total.frame <- data.frame(tree.a.re, tree.sources.frame)#
    colnames(tree.total.frame) <- c("to.test", names(tree.sources.frame))#
    trees.r2 <- apply(tree.sources.frame, 2, function(x) summary(lm(x~tree.a.re))$r.squared)#
    trees.n <- apply(tree.sources.frame, 2, function(x) length(summary(lm(x~tree.a.re))$residuals))#
    turn.to.t <- function(trees.rsquared, trees.residual.n) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- sqrt(trees.r2)*sqrt(trees.n-2)/sqrt(1-trees.r2)#
    trees.r <- sqrt(trees.r2)#
    result.frame <- data.frame(trees.t, trees.r, trees.n)#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnife <- function(time,  tree.dataframe, tree.source) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re <- tree.a.mod[tree.a.mod$Year %in% tree.b$Year, ]#
    tree.b.re <- tree.b[tree.b$Year %in% tree.a.mod$Year, ]#
    tree.a.re.re <- tree.a.re[2:samp.n]#
    source <- tree.b.re[,2]#
    n <- length(ls(tree.a.re))#
    group.lm.r2 <- apply(tree.a.re.re, 2, function(x) as.vector(summary(lm(x~source))$r.squared))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.lm.res.n <- apply(tree.a.re.re, 2, function(x) as.numeric(length(summary(lm(x~source))$residuals)))#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnifeAlt <- function(time,  tree.dataframe) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re.re <- tree.a.mod[2:samp.n]#
    n <- length(tree.a.re.re)#
    group.lm.r2 <- do.call("rbind", sapply(1:n, FUN = function(i) summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$r.squared, simplify=FALSE))#
    group.lm.res.n <- do.call("rbind", sapply(1:n, FUN = function(i) length(summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$residuals), simplify=FALSE))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
#
treeJackKnifeMultiple <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- data.frame(subListExtract(L=all.group.t, name="t-value"))#
    colnames(t.value) <- source.names#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSig <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.names <- names(tree.dataframe)#
    tree.names <- tree.names[2:length(tree.names)]#
    cat(gettext(tree.names))#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
#
t.value$Difference <- rep("Yes", length(t.value$Mean))#
t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
t.value.names <- names(t.value)#
#t.value <- data.frame(tree.names, t.value)#
#colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSigSamp <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.n <- length(tree.dataframe)#
    tree.names <- names(tree.dataframe[2:tree.n])#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
    t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    t.value <- data.frame(tree.names, t.value)#
    colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
#
percent <- function(x, digits = 2, format = "f", ...) {#
    paste0(formatC(100 * x, format = format, digits = digits, ...), "%")#
}#
#
populationSig <- function(x) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes"))#
    No <- length(subset(x$pvalue, x$Difference=="No"))#
    Ratio <- Yes/(sum(Yes, No))#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
}#
#
populationSigDefinition <- function(x, source.hypothesis) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes" & x$Source == source.hypothesis))#
    No <- length(x$pvalue)-Yes#
    Ratio <- Yes/length(x$pvalue)#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
#
}#
#
populationSigDefinitionMultiple <- function(x, source.hypotheses) {#
    hold <- rep(0, length(source.hypotheses))#
    hold.frame <- data.frame(t(hold))#
    colnames(hold.frame) <- source.hypotheses#
    n <- length(x$Difference)#
    x.subset <- subset(x, x$Difference=="Yes")#
    x.source <- table(x.subset$Source)#
    x.values <- as.numeric(paste(x.source))#
    x.frame <- data.frame(t(x.values))#
    colnames(x.frame) <- names(x.source)#
    Yes <- length(subset(x$Source, x$Difference=="Yes"))#
    None.n <- length(subset(x$Source, x$Difference=="No"))#
    None <- None.n/n#
    Ratio <- Yes/(Yes+None.n)#
    results.frame <- merge(hold.frame, x.frame, all=TRUE)#
    results.frame[is.na(results.frame)] <- 0#
    result.frame <- data.frame(results.frame[2,]/n, None, Ratio)#
    return(format(result.frame, digits=2))#
}#
#
multiplePopulationSig <- function(t.table.list) {#
         yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
         return(yes.no.table)#
     }#
#
test.list <- list(Chuska.JackKnife.t,Crystal.JackKnife.t)#
multiplePopulationSig(test.list)#
multiplePopulationSig <- function(x,...) {#
    yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
    return(yes.no.table)#
}#
#
treeBayes <- function () {#
    ####Prior Probability#
    prior.prob <- 1/length(source.names)#
    prior.opp <- 1-prior#
    ###Source Probability#
    source.prob <-#
    source.opp <-#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    prior <- 1/length(source.names)#
    prior.opp <- 1-prior#
    new <- 1-t.value$pvalue#
    opp <- t.value$pvalue#
    true.positive <- prior*new#
    false.positive <- prior.opp*opp#
    false.negative <- prior.opp*new#
    true.negative <- prior#
    t.value$Posterior <-#
}#
#
sourceGrid <- function(fileDirectory, sourceDefinitions, time, source.hypotheses) {#
    setwd(fileDirectory)#
    temp <- list.files(pattern="*.txt")#
    myRWL <- pblapply(temp, readRWLArima)#
    myJackKnife <- lapply(myRWL,  function(x) treeJackKnifeMultipleSourceSig(time, x, source.list, return="t-value"))#
    mySigDef <- lapply(myJackKnife, function(x) populationSigDefinitionMultiple(x, source.hypotheses))#
    myResults <- ldply (mySigDef, data.frame)#
    rownames(myResults) <- gsub(".txt", "", temp, )#
    return(myResults)#
}#
################
###Load Data####
################
####Define Time#
time <- seq(1600, 1900, 1)#
#
all <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco/All Guitermann Data.csv")#
#
CHU <- data.frame(all$Year, auto.arima(all$CHU)$residuals)#
colnames(CHU) <- c("Year", "CHU")#
#
CEB <- data.frame(all$Year, auto.arima(all$CEB)$residuals)#
colnames(CEB) <- c("Year", "CEB")#
#
CIB <- data.frame(all$Year, auto.arima(all$CIB)$residuals)#
colnames(CIB) <- c("Year", "CIB")#
#
GOB <- data.frame(all$Year, auto.arima(all$GOB)$residuals)#
colnames(GOB) <- c("Year", "GOB")#
#
JEM <- data.frame(all$Year, auto.arima(all$JEM)$residuals)#
colnames(JEM) <- c("Year", "JEM")#
#
MEA <- data.frame(all$Year, auto.arima(all$MEA)$residuals)#
colnames(MEA) <- c("Year", "MEA")#
#
MVER <- data.frame(all$Year, auto.arima(all$MVER)$residuals)#
colnames(MVER) <- c("Year", "MVER")#
#
DUR <- data.frame(all$Year, auto.arima(all$DUR)$residuals)#
colnames(DUR) <- c("Year", "DUR")#
#
source.hypotheses <- c("CHU","CEB","CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
all.sources <- data.frame(all$Year, all$CHU, all$CEB, all$CIB, all$GOB, all$JEM, all$MEA, all$MVER,  all$DUR)#
colnames(all.sources) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
MountTaylor <- readRWLArima(file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Chaco Sources/CEB.txt")
###MountTaylorJackKnife#
MountTaylor.JackKnife.t <- treeJackKnifeMultipleSourceSig(time, MountTaylor, source.list, return="t-value")#
MountTaylor.JackKnife.r <- treeJackKnifeMultiple(time, MountTaylor, source.list, return="r-value")#
MountTaylor.JackKnife.so <- treeJackKnifeMultiple(time, MountTaylor, source.list, return="Sample-Overlap")#
write.xlsx(MountTaylor.JackKnife.t, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/JackKnife/MountTaylorJackknife.xlsx", sheetName="T-Value")#
write.xlsx(MountTaylor.JackKnife.r, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/JackKnife/MountTaylorJackknife.xlsx", sheetName="R-Value", append=TRUE)#
write.xlsx(MountTaylor.JackKnife.so, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/JackKnife/MountTaylorJackknife.xlsx", sheetName="Overlap", append=TRUE)
MountTaylor.sig <- populationSigDefinition(MountTaylor.JackKnife.t, "CEB")
MountTaylor.sig
Gobernador.1 <- readRWLArima(file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/All/pueblitacanyon537.txt")
library(shiny)
runApp("~/GitHub/treeSource")
treeJackKnifeMultipleSourceSig( timemin = min(all$Year,), timemax=max(all$Year), tree.dataframe=all, tree.source.list=source.list)
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
####Define Time#
time <- seq(1600, 1900, 1)#
#
all <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco/All Guitermann Data.csv")#
#
CHU <- data.frame(all$Year, auto.arima(all$CHU)$residuals)#
colnames(CHU) <- c("Year", "CHU")#
#
CEB <- data.frame(all$Year, auto.arima(all$CEB)$residuals)#
colnames(CEB) <- c("Year", "CEB")#
#
CIB <- data.frame(all$Year, auto.arima(all$CIB)$residuals)#
colnames(CIB) <- c("Year", "CIB")#
#
GOB <- data.frame(all$Year, auto.arima(all$GOB)$residuals)#
colnames(GOB) <- c("Year", "GOB")#
#
JEM <- data.frame(all$Year, auto.arima(all$JEM)$residuals)#
colnames(JEM) <- c("Year", "JEM")#
#
MEA <- data.frame(all$Year, auto.arima(all$MEA)$residuals)#
colnames(MEA) <- c("Year", "MEA")#
#
MVER <- data.frame(all$Year, auto.arima(all$MVER)$residuals)#
colnames(MVER) <- c("Year", "MVER")#
#
DUR <- data.frame(all$Year, auto.arima(all$DUR)$residuals)#
colnames(DUR) <- c("Year", "DUR")#
#
source.hypotheses <- c("CHU","CEB","CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
all.sources <- data.frame(all$Year, all$CHU, all$CEB, all$CIB, all$GOB, all$JEM, all$MEA, all$MVER,  all$DUR)#
colnames(all.sources) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
treeJackKnifeMultipleSourceSig( timemin = min(all$Year,), timemax=max(all$Year), tree.dataframe=all, tree.source.list=source.list)
treeJackKnifeMultipleSourceSig( timemin = min(all$Year), timemax=max(all$Year), tree.dataframe=all, tree.source.list=source.list)
source.frame <- data.frame(CHU$Year, CHU$CHU, CEB$CEB, CIB$CIB, GOB$GOB, JEM$JEM, MEA$MEA, MVER$MVER, DUR$DUR)
head(source.frame)
colnames(source.frame) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")
head(source.frame)
source.val <- treeJackKnifeMultipleSourceSig( timemin = min(all$Year), timemax=max(all$Year), tree.dataframe=source.frame, tree.source.list=source.list)
head(source.val)
write.xlsx(source.val, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/comparions.xlsx")
source.val <- treeJackKnifeMultipleSourceSig( timemin = 1600, timemax=1900, tree.dataframe=source.frame, tree.source.list=source.list)
write.xlsx(source.val, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/comparions.xlsx")
28.09 + 32
28.09/60.09
ChacoSources <- read.csv(file="http://www.bleedrake.com/chacoTrees/posteriorprob.csv", stringsAsFactors=FALSE)
library(ggplot2)
bar.plot <- ggplot(ChacoSources, aes(OuterDate)) +#
geom_histogram(aes( fill=Source), alpha=0.9) +#
theme_light() +#
theme(legend.position = c(0, 1),#
legend.justification = c(0, 1)) +#
scale_x_continuous("Outer Date (A.D.)", breaks = seq(850, 1150, 50)) +#
scale_y_continuous("Count")#
bar.plot
###Copy and paste this script into the R console on your computer. It will be compatible with Windows, Mac, and Linux.#
#
###All sentences beginning with "###" will be invisible to the software, and will caption and describe each step of the analysis and figures for [CITATION]#
#
###Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
###Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###IMPORTANT NOTE: R uses packages to facilitate the analysis of data and production of figures. If you do not have the TTR, bcp, or ggplot2 packages installed, the following three lines of text will do it for you - all you have to do is delete the "###" that precedes the commands#
#
###The command below will bring up a list of download sites. Pick one closest to you to speed up the download process#
###chooseCRANmirror()#
#
###The script below will then install the TTR package (for moving averages), bcp package (for Bayesian Change-Point analysis), and ggplot2 (for generating data plots)#
###Note: Installation of packages may take up to an hour, depending upon the speed of your internect connection. #
###install.packages("TTR", dependencies = TRUE)#
###install.packages("bcp", dependencies = TRUE)#
###install.packages("ggplot2", dependencies = TRUE)#
#
###Activate the packages#
#
library(ggplot2)#
library(gridExtra)#
library(dplR)#
library(pbapply)#
library(reshape)#
library(reshape2)#
library(Biobase)#
library(xlsx)#
library(forecast)#
library(ggmap)#
library(plyr)#
library(akima)#
#####Functions#
####Function to organize plots in a window#
layOut = function(...) {#
    require(grid)#
    x <- list(...)#
    n <- max(sapply(x, function(x) max(x[[2]])))#
    p <- max(sapply(x, function(x) max(x[[3]])))#
    pushViewport(viewport(layout = grid.layout(n, p)))#
    for (i in seq_len(length(x))) {#
        print(x[[i]][[1]], vp = viewport(layout.pos.row = x[[i]][[2]],#
        layout.pos.col = x[[i]][[3]]))#
    }#
}#
lm.dat <- function (formula, data, subset, weights, na.action, method = "qr",#
model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,#
contrasts = NULL, offset, ...)#
{#
    dat.fram <- data.frame(x, y)#
    dat.fram <- dat.fram[complete.cases(dat.fram),]#
    x <- dat.fram$x#
    y <- dat.fram$y#
    ret.x <- x#
    ret.y <- y#
    cl <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
    m <- match(c("formula", "data", "subset", "weights", "na.action",#
    "offset"), names(mf), 0L)#
    mf <- mf[c(1L, m)]#
    mf$drop.unused.levels <- TRUE#
    mf[[1L]] <- quote(stats::model.frame)#
    mf <- eval(mf, parent.frame())#
    if (method == "model.frame")#
    return(mf)#
    else if (method != "qr")#
    warning(gettextf("method = '%s' is not supported. Using 'qr'",#
    method), domain = NA)#
    mt <- attr(mf, "terms")#
    y <- model.response(mf, "numeric")#
    w <- as.vector(model.weights(mf))#
    if (!is.null(w) && !is.numeric(w))#
    stop("'weights' must be a numeric vector")#
    offset <- as.vector(model.offset(mf))#
    if (!is.null(offset)) {#
        if (length(offset) != NROW(y))#
        stop(gettextf("number of offsets is %d, should equal %d (number of observations)",#
        length(offset), NROW(y)), domain = NA)#
    }#
    if (is.empty.model(mt)) {#
        x <- NULL#
        z <- list(coefficients = if (is.matrix(y)) matrix(, 0,#
        3) else numeric(), residuals = y, fitted.values = 0 *#
        y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w !=#
        0) else if (is.matrix(y)) nrow(y) else length(y))#
        if (!is.null(offset)) {#
            z$fitted.values <- offset#
            z$residuals <- y - offset#
        }#
    }#
    else {#
        x <- model.matrix(mt, mf, contrasts)#
        z <- if (is.null(w))#
        lm.fit(x, y, offset = offset, singular.ok = singular.ok,#
        ...)#
        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok,#
        ...)#
    }#
    class(z) <- c(if (is.matrix(y)) "mlm", "lm")#
    z$na.action <- attr(mf, "na.action")#
    z$offset <- offset#
    z$contrasts <- attr(x, "contrasts")#
    z$xlevels <- .getXlevels(mt, mf)#
    z$call <- cl#
    z$terms <- mt#
    if (model)#
    z$model <- mf#
    if (ret.x)#
    z$x <- x#
    if (ret.y)#
    z$y <- y#
    if (!qr)#
    z$qr <- NULL#
    z#
}#
#
unlist.tree <- function(temp, myfiles){#
    n <- length(temp)#
    for (i in n) {#
        temp[i] <- myfiles[[i]]#
    }#
}#
#
ig.na <- function(x) {#
    length(na.omit(x))#
}#
#
nonNAs <- function(x) {#
    n <- as.vector(apply(x, 1, function(x) length(which(!is.na(x)))))#
    return(n)#
}#
#
readRWL.simp <- function(file) {#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    non.total <- data.frame(years, raw)#
    colnames(non.total)[1] <- "Year"#
    return(non.total)#
}#
#
readRWLArima <- function(file) {#
    raw <- read.rwl(file)#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    detrended <- data.frame(detrend(raw, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="residuals"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
#
readDataArima <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    arima.data <- pbapply(X=detrended, MARGIN=2, function(x) FUN=auto.arima(x)$residuals)#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArimaFit <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, function(x) FUN=fitted(auto.arima(x)))#
    arima.total <- data.frame(years, list.arima)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArima4 <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline"))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="x"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
meanSequence <- function(tree.dataframe, name) {#
    n <- length(tree.dataframe)#
    sequ <- rowMeans(tree.dataframe[2:n], na.rm=TRUE)#
    results.frame <- data.frame(as.numeric(as.vector(tree.dataframe$Year)), sequ)#
    colnames(results.frame) <- c("Year", name)#
    return(results.frame)#
}#
#
treeHypothesis <- function(time, tree.dataframe.1, tree.dataframe.2) {#
    tree.a <- tree.dataframe.1[match(time, tree.dataframe.1$Year, nomatch=0),]#
    tree.b <- tree.dataframe.2[match(time, tree.dataframe.2$Year, nomatch=0),]#
    df <- data.frame(time, tree.a$Mean, tree.b$Mean, tree.a$SD, tree.b$SD, tree.a$N, tree.b$N)#
    colnames(df) <- c("Year", "FirstMean", "SecondMean", "FirstSD", "SecondSD", "FirstN", "SecondN")#
    df$Ttest <- c(abs(df$FirstMean-df$SecondMean)/(sqrt((df$FirstSD^2)/df$FirstN + (df$SecondSD^2)/df$SecondN)))#
    df$DF <- c(((((df$FirstSD^2)/df$FirstN) +  ((df$SecondSD^2)/df$SecondN))^2)/((df$FirstSD^4)/((df$FirstN^2)*(df$FirstN-1)) + (df$SecondSD^4)/((df$SecondN^2)*(df$SecondN-1))))#
    df$pvalue <- c((2*pt(df$Ttest, df$DF, lower=FALSE)))#
    df$Significant <- rep("Yes", length(df$Year))#
    df <- transform(df, Significant = ifelse(pvalue > 0.05, "No", Significant))#
    return(df)#
}#
#
sigCount <- function(tree.hypothesis.test.results) {#
    Yes <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="Yes")#
    No <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="No")#
    Yess <- length(Yes)#
    Nos <- length(No)#
    results <- data.frame(mean(Yes), mean(No), Yess, Nos)#
    colnames(results) <- c("p-value diff", "p-value same", "p < 0.05", "p > 0.05")#
    return(results)#
}#
treeCorTest <- function(time, tree.object, tree.source){#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- data.frame(tree.b$Year, tree.b[,2])#
    colnames(tree.b.frame) <- c("Year", "B")#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- tree.b.frame$B[tree.b.frame$Year %in% tree.a$Year]#
    trees.grid <- data.frame(tree.a.re, tree.b.re)#
    colnames(trees.grid) <- c("First", "Second")#
    trees.lm <- lm(trees.grid$First~trees.grid$Second)#
    trees.s.lm <- summary(trees.lm)#
    turn.to.t <- function(x.lm) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- turn.to.t(trees.lm)#
    result.frame <- data.frame(trees.t,sqrt(trees.s.lm$r.squared), length(trees.lm$residuals))#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(result.frame)#
}#
treeCorTestMultiple <- function(time, tree.object, tree.sources){#
    tree.sources.n <- length(tree.sources)#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.sources[match(time, tree.sources$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- tree.b#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- semi_join(tree.b.frame, tree.a.frame, by="Year")#
    tree.sources.frame <- tree.b.re[2:tree.sources.n]#
    colnames(tree.sources.frame) <- names(tree.sources[2:tree.sources.n])#
    tree.total.frame <- data.frame(tree.a.re, tree.sources.frame)#
    colnames(tree.total.frame) <- c("to.test", names(tree.sources.frame))#
    trees.r2 <- apply(tree.sources.frame, 2, function(x) summary(lm(x~tree.a.re))$r.squared)#
    trees.n <- apply(tree.sources.frame, 2, function(x) length(summary(lm(x~tree.a.re))$residuals))#
    turn.to.t <- function(trees.rsquared, trees.residual.n) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- sqrt(trees.r2)*sqrt(trees.n-2)/sqrt(1-trees.r2)#
    trees.r <- sqrt(trees.r2)#
    result.frame <- data.frame(trees.t, trees.r, trees.n)#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnife <- function(time,  tree.dataframe, tree.source) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re <- tree.a.mod[tree.a.mod$Year %in% tree.b$Year, ]#
    tree.b.re <- tree.b[tree.b$Year %in% tree.a.mod$Year, ]#
    tree.a.re.re <- tree.a.re[2:samp.n]#
    source <- tree.b.re[,2]#
    n <- length(ls(tree.a.re))#
    group.lm.r2 <- apply(tree.a.re.re, 2, function(x) as.vector(summary(lm(x~source))$r.squared))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.lm.res.n <- apply(tree.a.re.re, 2, function(x) as.numeric(length(summary(lm(x~source))$residuals)))#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnifeAlt <- function(time,  tree.dataframe) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re.re <- tree.a.mod[2:samp.n]#
    n <- length(tree.a.re.re)#
    group.lm.r2 <- do.call("rbind", sapply(1:n, FUN = function(i) summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$r.squared, simplify=FALSE))#
    group.lm.res.n <- do.call("rbind", sapply(1:n, FUN = function(i) length(summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$residuals), simplify=FALSE))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
#
treeJackKnifeMultiple <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- data.frame(subListExtract(L=all.group.t, name="t-value"))#
    colnames(t.value) <- source.names#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSig <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.names <- names(tree.dataframe)#
    tree.names <- tree.names[2:length(tree.names)]#
    cat(gettext(tree.names))#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
#
t.value$Difference <- rep("Yes", length(t.value$Mean))#
t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
t.value.names <- names(t.value)#
#t.value <- data.frame(tree.names, t.value)#
#colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSigSamp <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.n <- length(tree.dataframe)#
    tree.names <- names(tree.dataframe[2:tree.n])#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
    t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    t.value <- data.frame(tree.names, t.value)#
    colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
#
percent <- function(x, digits = 2, format = "f", ...) {#
    paste0(formatC(100 * x, format = format, digits = digits, ...), "%")#
}#
#
populationSig <- function(x) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes"))#
    No <- length(subset(x$pvalue, x$Difference=="No"))#
    Ratio <- Yes/(sum(Yes, No))#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
}#
#
populationSigDefinition <- function(x, source.hypothesis) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes" & x$Source == source.hypothesis))#
    No <- length(x$pvalue)-Yes#
    Ratio <- Yes/length(x$pvalue)#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
#
}#
#
populationSigDefinitionMultiple <- function(x, source.hypotheses) {#
    hold <- rep(0, length(source.hypotheses))#
    hold.frame <- data.frame(t(hold))#
    colnames(hold.frame) <- source.hypotheses#
    n <- length(x$Difference)#
    x.subset <- subset(x, x$Difference=="Yes")#
    x.source <- table(x.subset$Source)#
    x.values <- as.numeric(paste(x.source))#
    x.frame <- data.frame(t(x.values))#
    colnames(x.frame) <- names(x.source)#
    Yes <- length(subset(x$Source, x$Difference=="Yes"))#
    None.n <- length(subset(x$Source, x$Difference=="No"))#
    None <- None.n/n#
    Ratio <- Yes/(Yes+None.n)#
    results.frame <- merge(hold.frame, x.frame, all=TRUE)#
    results.frame[is.na(results.frame)] <- 0#
    result.frame <- data.frame(results.frame[2,]/n, None, Ratio)#
    return(format(result.frame, digits=2))#
}#
#
multiplePopulationSig <- function(t.table.list) {#
         yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
         return(yes.no.table)#
     }#
#
test.list <- list(Chuska.JackKnife.t,Crystal.JackKnife.t)#
multiplePopulationSig(test.list)#
multiplePopulationSig <- function(x,...) {#
    yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
    return(yes.no.table)#
}#
#
treeBayes <- function () {#
    ####Prior Probability#
    prior.prob <- 1/length(source.names)#
    prior.opp <- 1-prior#
    ###Source Probability#
    source.prob <-#
    source.opp <-#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    prior <- 1/length(source.names)#
    prior.opp <- 1-prior#
    new <- 1-t.value$pvalue#
    opp <- t.value$pvalue#
    true.positive <- prior*new#
    false.positive <- prior.opp*opp#
    false.negative <- prior.opp*new#
    true.negative <- prior#
    t.value$Posterior <-#
}#
#
sourceGrid <- function(fileDirectory, sourceDefinitions, time, source.hypotheses) {#
    setwd(fileDirectory)#
    temp <- list.files(pattern="*.txt")#
    myRWL <- pblapply(temp, readRWLArima)#
    myJackKnife <- lapply(myRWL,  function(x) treeJackKnifeMultipleSourceSig(time, x, source.list, return="t-value"))#
    mySigDef <- lapply(myJackKnife, function(x) populationSigDefinitionMultiple(x, source.hypotheses))#
    myResults <- ldply (mySigDef, data.frame)#
    rownames(myResults) <- gsub(".txt", "", temp, )#
    return(myResults)#
}#
################
###Load Data####
################
####Define Time#
time <- seq(1600, 1900, 1)#
#
all <- read.csv(file="http://www.bleedrake.com/chacoTrees/guitermann2017.csv")#
#
CHU <- data.frame(all$Year, auto.arima(all$CHU)$residuals)#
colnames(CHU) <- c("Year", "CHU")#
#
CEB <- data.frame(all$Year, auto.arima(all$CEB)$residuals)#
colnames(CEB) <- c("Year", "CEB")#
#
CIB <- data.frame(all$Year, auto.arima(all$CIB)$residuals)#
colnames(CIB) <- c("Year", "CIB")#
#
GOB <- data.frame(all$Year, auto.arima(all$GOB)$residuals)#
colnames(GOB) <- c("Year", "GOB")#
#
JEM <- data.frame(all$Year, auto.arima(all$JEM)$residuals)#
colnames(JEM) <- c("Year", "JEM")#
#
MEA <- data.frame(all$Year, auto.arima(all$MEA)$residuals)#
colnames(MEA) <- c("Year", "MEA")#
#
MVER <- data.frame(all$Year, auto.arima(all$MVER)$residuals)#
colnames(MVER) <- c("Year", "MVER")#
#
DUR <- data.frame(all$Year, auto.arima(all$DUR)$residuals)#
colnames(DUR) <- c("Year", "DUR")#
#
source.hypotheses <- c("CHU","CEB","CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.frame <- data.frame(CHU$Year, CHU$CHU, CEB$CEB, CIB$CIB, GOB$GOB, JEM$JEM, MEA$MEA, MVER$MVER, DUR$DUR)#
colnames(source.frame) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
all.sources <- data.frame(all$Year, all$CHU, all$CEB, all$CIB, all$GOB, all$JEM, all$MEA, all$MVER,  all$DUR)#
colnames(all.sources) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
testResults <- sourceGrid(fileDirectory="http://www.bleedrake.com/chacoTrees/Sources", sourceDefinitions=source.list, time=time, source.hypotheses=source.hypotheses)
library(Bchronology)
library(BChron)
library(Bchron)
BchronCalibrate(ages=1025,ageSds=85, calCurves="intcal13" )
median(BchronCalibrate(ages=1025,ageSds=85, calCurves="intcal13" )$ageGrid)
median(BchronCalibrate(ages=1025,ageSds=85, calCurves="intcal13" )Date1$ageGrid)
median(BchronCalibrate(ages=1025,ageSds=85, calCurves="intcal13" )$Date1$ageGrid)
sd(BchronCalibrate(ages=1025,ageSds=85, calCurves="intcal13" )$Date1$ageGrid)
sd(BchronCalibrate(ages=2170,ageSds=110, calCurves="intcal13" )$Date1$ageGrid)
median(BchronCalibrate(ages=2170,ageSds=110, calCurves="intcal13" )$Date1$ageGrid)
median(BchronCalibrate(ages=1655,ageSds=85, calCurves="intcal13" )$Date1$ageGrid)
sd(BchronCalibrate(ages=1655,ageSds=85, calCurves="intcal13" )$Date1$ageGrid)
🌀
☠️
👀
👽
ages <- c(1655, 2170, 1025)
sigma <- c(85, 110, 85)
depth <- c(204, 190, 140)
?Bchron
test <- Bchronology(ages=ages, ageSds=sigma, positions=depth, calcurves(c("intcal13", "intcal13", "intcal13")))
test <- Bchronology(ages=ages, ageSds=sigma, positions=depth, calCurves(c("intcal13", "intcal13", "intcal13")))
test <- Bchronology(ages=ages, ageSds=sigma, positions=depth, calCurves=(c("intcal13", "intcal13", "intcal13")))
test <- Bchronology(ages=ages, ageSds=sigma, positions=depth,positionThicknesses=c(30, 30, 30) ,calCurves=(c("intcal13", "intcal13", "intcal13")))
test <- Bchronology(ages=ages, ageSds=sigma, positions=depth,positionThicknesses=c(30, 30, 30) ,calCurves=(c("intcal13", "intcal13", "intcal13")), predictPositions=seq(63.7, 250, 2.3))
plot(test)
ls(test)
head(test$extractDate)
head(test$predictPositions)
head(test)
write.table(test$thetaPredict, file="~/pos.csv", sep=",")
library(shiny)
runApp("~/Dropbox/Application Code/XRF/xrf-app")
###Copy and paste this script into the R console on your computer. It will be compatible with Windows, Mac, and Linux.#
#
###All sentences beginning with "###" will be invisible to the software, and will caption and describe each step of the analysis and figures for [CITATION]#
#
###Erase everything that comes before#
rm(list = ls(all = TRUE))#
#
###Compatibility#
if(.Platform$OS.type=="windows") {#
  quartz<-function() windows()#
}#
#
###IMPORTANT NOTE: R uses packages to facilitate the analysis of data and production of figures. If you do not have the TTR, bcp, or ggplot2 packages installed, the following three lines of text will do it for you - all you have to do is delete the "###" that precedes the commands#
#
###The command below will bring up a list of download sites. Pick one closest to you to speed up the download process#
###chooseCRANmirror()#
#
###The script below will then install the TTR package (for moving averages), bcp package (for Bayesian Change-Point analysis), and ggplot2 (for generating data plots)#
###Note: Installation of packages may take up to an hour, depending upon the speed of your internect connection. #
###install.packages("TTR", dependencies = TRUE)#
###install.packages("bcp", dependencies = TRUE)#
###install.packages("ggplot2", dependencies = TRUE)#
#
###Activate the packages#
#
library(ggplot2)#
library(gridExtra)#
library(dplR)#
library(pbapply)#
library(reshape)#
library(reshape2)#
library(Biobase)#
library(xlsx)#
library(forecast)#
library(ggmap)#
library(plyr)#
library(akima)#
#####Functions#
####Function to organize plots in a window#
layOut = function(...) {#
    require(grid)#
    x <- list(...)#
    n <- max(sapply(x, function(x) max(x[[2]])))#
    p <- max(sapply(x, function(x) max(x[[3]])))#
    pushViewport(viewport(layout = grid.layout(n, p)))#
    for (i in seq_len(length(x))) {#
        print(x[[i]][[1]], vp = viewport(layout.pos.row = x[[i]][[2]],#
        layout.pos.col = x[[i]][[3]]))#
    }#
}#
lm.dat <- function (formula, data, subset, weights, na.action, method = "qr",#
model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,#
contrasts = NULL, offset, ...)#
{#
    dat.fram <- data.frame(x, y)#
    dat.fram <- dat.fram[complete.cases(dat.fram),]#
    x <- dat.fram$x#
    y <- dat.fram$y#
    ret.x <- x#
    ret.y <- y#
    cl <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
    m <- match(c("formula", "data", "subset", "weights", "na.action",#
    "offset"), names(mf), 0L)#
    mf <- mf[c(1L, m)]#
    mf$drop.unused.levels <- TRUE#
    mf[[1L]] <- quote(stats::model.frame)#
    mf <- eval(mf, parent.frame())#
    if (method == "model.frame")#
    return(mf)#
    else if (method != "qr")#
    warning(gettextf("method = '%s' is not supported. Using 'qr'",#
    method), domain = NA)#
    mt <- attr(mf, "terms")#
    y <- model.response(mf, "numeric")#
    w <- as.vector(model.weights(mf))#
    if (!is.null(w) && !is.numeric(w))#
    stop("'weights' must be a numeric vector")#
    offset <- as.vector(model.offset(mf))#
    if (!is.null(offset)) {#
        if (length(offset) != NROW(y))#
        stop(gettextf("number of offsets is %d, should equal %d (number of observations)",#
        length(offset), NROW(y)), domain = NA)#
    }#
    if (is.empty.model(mt)) {#
        x <- NULL#
        z <- list(coefficients = if (is.matrix(y)) matrix(, 0,#
        3) else numeric(), residuals = y, fitted.values = 0 *#
        y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w !=#
        0) else if (is.matrix(y)) nrow(y) else length(y))#
        if (!is.null(offset)) {#
            z$fitted.values <- offset#
            z$residuals <- y - offset#
        }#
    }#
    else {#
        x <- model.matrix(mt, mf, contrasts)#
        z <- if (is.null(w))#
        lm.fit(x, y, offset = offset, singular.ok = singular.ok,#
        ...)#
        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok,#
        ...)#
    }#
    class(z) <- c(if (is.matrix(y)) "mlm", "lm")#
    z$na.action <- attr(mf, "na.action")#
    z$offset <- offset#
    z$contrasts <- attr(x, "contrasts")#
    z$xlevels <- .getXlevels(mt, mf)#
    z$call <- cl#
    z$terms <- mt#
    if (model)#
    z$model <- mf#
    if (ret.x)#
    z$x <- x#
    if (ret.y)#
    z$y <- y#
    if (!qr)#
    z$qr <- NULL#
    z#
}#
#
unlist.tree <- function(temp, myfiles){#
    n <- length(temp)#
    for (i in n) {#
        temp[i] <- myfiles[[i]]#
    }#
}#
#
ig.na <- function(x) {#
    length(na.omit(x))#
}#
#
nonNAs <- function(x) {#
    n <- as.vector(apply(x, 1, function(x) length(which(!is.na(x)))))#
    return(n)#
}#
#
readRWL.simp <- function(file) {#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    non.total <- data.frame(years, raw)#
    colnames(non.total)[1] <- "Year"#
    return(non.total)#
}#
#
readRWLArima <- function(file) {#
    raw <- read.rwl(file)#
    raw <- read.rwl(file)#
    years <- rownames(raw)#
    detrended <- data.frame(detrend(raw, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="residuals"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
#
readDataArima <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    arima.data <- pbapply(X=detrended, MARGIN=2, function(x) FUN=auto.arima(x)$residuals)#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArimaFit <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline", nyrs=50))#
    list.arima <- pbapply(X=detrended, MARGIN=2, function(x) FUN=fitted(auto.arima(x)))#
    arima.total <- data.frame(years, list.arima)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
readDataArima4 <- function(file) {#
    raw <- read.csv(file)#
    n <- length(raw)#
    years <- raw[,1]#
    data <- raw[,2:n]#
    detrended <- data.frame(detrend(data, method="Spline"))#
    list.arima <- pbapply(X=detrended, MARGIN=2, FUN=auto.arima)#
    arima.data <- data.frame(subListExtract(L=list.arima, name="x"))#
    arima.total <- data.frame(years, arima.data)#
    colnames(arima.total)[1] <- "Year"#
    return(arima.total)#
}#
meanSequence <- function(tree.dataframe, name) {#
    n <- length(tree.dataframe)#
    sequ <- rowMeans(tree.dataframe[2:n], na.rm=TRUE)#
    results.frame <- data.frame(as.numeric(as.vector(tree.dataframe$Year)), sequ)#
    colnames(results.frame) <- c("Year", name)#
    return(results.frame)#
}#
#
treeHypothesis <- function(time, tree.dataframe.1, tree.dataframe.2) {#
    tree.a <- tree.dataframe.1[match(time, tree.dataframe.1$Year, nomatch=0),]#
    tree.b <- tree.dataframe.2[match(time, tree.dataframe.2$Year, nomatch=0),]#
    df <- data.frame(time, tree.a$Mean, tree.b$Mean, tree.a$SD, tree.b$SD, tree.a$N, tree.b$N)#
    colnames(df) <- c("Year", "FirstMean", "SecondMean", "FirstSD", "SecondSD", "FirstN", "SecondN")#
    df$Ttest <- c(abs(df$FirstMean-df$SecondMean)/(sqrt((df$FirstSD^2)/df$FirstN + (df$SecondSD^2)/df$SecondN)))#
    df$DF <- c(((((df$FirstSD^2)/df$FirstN) +  ((df$SecondSD^2)/df$SecondN))^2)/((df$FirstSD^4)/((df$FirstN^2)*(df$FirstN-1)) + (df$SecondSD^4)/((df$SecondN^2)*(df$SecondN-1))))#
    df$pvalue <- c((2*pt(df$Ttest, df$DF, lower=FALSE)))#
    df$Significant <- rep("Yes", length(df$Year))#
    df <- transform(df, Significant = ifelse(pvalue > 0.05, "No", Significant))#
    return(df)#
}#
#
sigCount <- function(tree.hypothesis.test.results) {#
    Yes <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="Yes")#
    No <- subset(tree.hypothesis.test.results$pvalue, tree.hypothesis.test.results$Significant=="No")#
    Yess <- length(Yes)#
    Nos <- length(No)#
    results <- data.frame(mean(Yes), mean(No), Yess, Nos)#
    colnames(results) <- c("p-value diff", "p-value same", "p < 0.05", "p > 0.05")#
    return(results)#
}#
treeCorTest <- function(time, tree.object, tree.source){#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- data.frame(tree.b$Year, tree.b[,2])#
    colnames(tree.b.frame) <- c("Year", "B")#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- tree.b.frame$B[tree.b.frame$Year %in% tree.a$Year]#
    trees.grid <- data.frame(tree.a.re, tree.b.re)#
    colnames(trees.grid) <- c("First", "Second")#
    trees.lm <- lm(trees.grid$First~trees.grid$Second)#
    trees.s.lm <- summary(trees.lm)#
    turn.to.t <- function(x.lm) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- turn.to.t(trees.lm)#
    result.frame <- data.frame(trees.t,sqrt(trees.s.lm$r.squared), length(trees.lm$residuals))#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(result.frame)#
}#
treeCorTestMultiple <- function(time, tree.object, tree.sources){#
    tree.sources.n <- length(tree.sources)#
    tree.a <- tree.object[match(time, tree.object$Year, nomatch=0),]#
    tree.b <- tree.sources[match(time, tree.sources$Year, nomatch=0),]#
    tree.a <- tree.a[complete.cases(tree.a), ]#
    tree.b <- tree.b[complete.cases(tree.b), ]#
    tree.a.arima <-arima(tree.a[,2], order=c(1, 0 ,1))#
    tree.a.n <- tree.a.arima$residuals#
    #tree.b.arima <-arima(tree.b[,2], order=c(1, 0 ,1))#
    #tree.b.n <- tree.b.arima$residuals#
    tree.a.frame <- data.frame(tree.a$Year, tree.a.n)#
    colnames(tree.a.frame) <- c("Year", "A")#
    tree.b.frame <- tree.b#
    tree.a.re <- tree.a.frame$A[tree.a.frame$Year %in% tree.b$Year]#
    tree.b.re <- semi_join(tree.b.frame, tree.a.frame, by="Year")#
    tree.sources.frame <- tree.b.re[2:tree.sources.n]#
    colnames(tree.sources.frame) <- names(tree.sources[2:tree.sources.n])#
    tree.total.frame <- data.frame(tree.a.re, tree.sources.frame)#
    colnames(tree.total.frame) <- c("to.test", names(tree.sources.frame))#
    trees.r2 <- apply(tree.sources.frame, 2, function(x) summary(lm(x~tree.a.re))$r.squared)#
    trees.n <- apply(tree.sources.frame, 2, function(x) length(summary(lm(x~tree.a.re))$residuals))#
    turn.to.t <- function(trees.rsquared, trees.residual.n) {#
        x.s.lm <- summary(x.lm)#
        r.sq <- x.s.lm$r.squared#
        just.r <- sqrt(r.sq)#
        t <- (just.r*sqrt(length(x.lm$residuals)-2))/sqrt(1-r.sq)#
        return(t)#
    }#
    trees.t <- sqrt(trees.r2)*sqrt(trees.n-2)/sqrt(1-trees.r2)#
    trees.r <- sqrt(trees.r2)#
    result.frame <- data.frame(trees.t, trees.r, trees.n)#
    colnames(result.frame) <- c("t", "r", "overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnife <- function(time,  tree.dataframe, tree.source) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.b <- tree.source[match(time, tree.source$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re <- tree.a.mod[tree.a.mod$Year %in% tree.b$Year, ]#
    tree.b.re <- tree.b[tree.b$Year %in% tree.a.mod$Year, ]#
    tree.a.re.re <- tree.a.re[2:samp.n]#
    source <- tree.b.re[,2]#
    n <- length(ls(tree.a.re))#
    group.lm.r2 <- apply(tree.a.re.re, 2, function(x) as.vector(summary(lm(x~source))$r.squared))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.lm.res.n <- apply(tree.a.re.re, 2, function(x) as.numeric(length(summary(lm(x~source))$residuals)))#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
treeJackKnifeAlt <- function(time,  tree.dataframe) {#
    tree.a <- tree.dataframe[match(time, tree.dataframe$Year, nomatch=0),]#
    tree.a.mod <- tree.a[, colSums(is.na(tree.a)) != nrow(tree.a)]#
    samp.n <- length(names(tree.a.mod))#
    tree.names <- names(tree.a.mod[2:samp.n])#
    tree.a.re.re <- tree.a.mod[2:samp.n]#
    n <- length(tree.a.re.re)#
    group.lm.r2 <- do.call("rbind", sapply(1:n, FUN = function(i) summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$r.squared, simplify=FALSE))#
    group.lm.res.n <- do.call("rbind", sapply(1:n, FUN = function(i) length(summary(lm(tree.a.re.re[,i]~as.vector(rowMeans(tree.a.re.re[,-i], na.rm=TRUE))))$residuals), simplify=FALSE))#
    group.lm.r <- sqrt(group.lm.r2)#
    group.t <- sqrt(group.lm.r2)*sqrt(group.lm.res.n-2)/sqrt(1-group.lm.r2)#
    result.frame <- data.frame(group.t, group.lm.r, group.lm.res.n)#
    colnames(result.frame) <- c("t-value", "r-value", "Sample Overlap")#
    return(format(result.frame, digits=3))#
}#
#
treeJackKnifeMultiple <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- data.frame(subListExtract(L=all.group.t, name="t-value"))#
    colnames(t.value) <- source.names#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSig <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.names <- names(tree.dataframe)#
    tree.names <- tree.names[2:length(tree.names)]#
    cat(gettext(tree.names))#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
#
t.value$Difference <- rep("Yes", length(t.value$Mean))#
t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
t.value.names <- names(t.value)#
#t.value <- data.frame(tree.names, t.value)#
#colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
treeJackKnifeMultipleSourceSigSamp <- function(time, tree.dataframe, tree.source.list, return = c("t-value", "r-value", "Sample-Overlap")) {#
    tree.n <- length(tree.dataframe)#
    tree.names <- names(tree.dataframe[2:tree.n])#
    source.name.list <- sapply(tree.source.list, names)#
    source.names <- source.name.list[2,]#
    all.group.t <- pblapply(tree.source.list, function(tree.source.list) treeJackKnife(time, tree.dataframe, tree.source.list))#
    t.value <- as.data.frame(subListExtract(L=all.group.t, name="t-value"), stringsAsFactors=TRUE)#
    colnames(t.value) <- source.names#
    n <- length(names(t.value))#
    t.value <- as.data.frame(lapply(t.value, as.numeric))#
    scaled.t <- t(apply(t.value, 1, function(x) scale(x)[,1]))#
    t.value$Mean <- rowMeans(t.value)#
    scaled.mean <- rowMeans(scaled.t)#
    t.value$SD <- apply(t.value, 1, sd)#
    scaled.sd <- apply(scaled.t, 1, sd)#
    t.value$SourceValue <- apply(t.value, 1, max)#
    scaled.max.value <- apply(scaled.t, 1, max)#
    t.value$Source <- colnames(t.value)[apply(t.value,1,which.max)]#
    t.value$ZScore <- (scaled.max.value-scaled.mean)/scaled.sd#
    t.value$pvalue <- pnorm(-abs(t.value$ZScore))#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    t.value <- data.frame(tree.names, t.value)#
    colnames(t.value) <- c("Specimen", t.value.names)#
    r.value <- data.frame(subListExtract(L=all.group.t, name="r-value"))#
    colnames(r.value) <- source.names#
    samp.over <- data.frame(subListExtract(L=all.group.t, name="Sample Overlap"))#
    colnames(samp.over) <- source.names#
    result <- if (return=="t-value") {#
        t.value#
    } else if (return=="r-value") {#
        r.value#
    } else if (return=="Sample-Overlap") {#
        samp.over#
    }#
    return(format(result, digits=3))#
}#
#
percent <- function(x, digits = 2, format = "f", ...) {#
    paste0(formatC(100 * x, format = format, digits = digits, ...), "%")#
}#
#
populationSig <- function(x) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes"))#
    No <- length(subset(x$pvalue, x$Difference=="No"))#
    Ratio <- Yes/(sum(Yes, No))#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
}#
#
populationSigDefinition <- function(x, source.hypothesis) {#
    Yes <- length(subset(x$pvalue, x$Difference=="Yes" & x$Source == source.hypothesis))#
    No <- length(x$pvalue)-Yes#
    Ratio <- Yes/length(x$pvalue)#
    result.frame <- data.frame(Yes, No, Ratio)#
    return(format(result.frame, digits=3))#
#
}#
#
populationSigDefinitionMultiple <- function(x, source.hypotheses) {#
    hold <- rep(0, length(source.hypotheses))#
    hold.frame <- data.frame(t(hold))#
    colnames(hold.frame) <- source.hypotheses#
    n <- length(x$Difference)#
    x.subset <- subset(x, x$Difference=="Yes")#
    x.source <- table(x.subset$Source)#
    x.values <- as.numeric(paste(x.source))#
    x.frame <- data.frame(t(x.values))#
    colnames(x.frame) <- names(x.source)#
    Yes <- length(subset(x$Source, x$Difference=="Yes"))#
    None.n <- length(subset(x$Source, x$Difference=="No"))#
    None <- None.n/n#
    Ratio <- Yes/(Yes+None.n)#
    results.frame <- merge(hold.frame, x.frame, all=TRUE)#
    results.frame[is.na(results.frame)] <- 0#
    result.frame <- data.frame(results.frame[2,]/n, None, Ratio)#
    return(format(result.frame, digits=2))#
}#
#
multiplePopulationSig <- function(t.table.list) {#
         yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
         return(yes.no.table)#
     }#
#
test.list <- list(Chuska.JackKnife.t,Crystal.JackKnife.t)#
multiplePopulationSig(test.list)#
multiplePopulationSig <- function(x,...) {#
    yes.no.table <- as.data.frame(sapply(t.table.list, FUN=populationSig, USE.NAMES=TRUE))#
    return(yes.no.table)#
}#
#
treeBayes <- function () {#
    ####Prior Probability#
    prior.prob <- 1/length(source.names)#
    prior.opp <- 1-prior#
    ###Source Probability#
    source.prob <-#
    source.opp <-#
    t.value$Difference <- rep("Yes", length(t.value$Mean))#
    t.value <- transform(t.value, Difference = ifelse(pvalue > 0.05, "No", Difference))#
    t.value.names <- names(t.value)#
    prior <- 1/length(source.names)#
    prior.opp <- 1-prior#
    new <- 1-t.value$pvalue#
    opp <- t.value$pvalue#
    true.positive <- prior*new#
    false.positive <- prior.opp*opp#
    false.negative <- prior.opp*new#
    true.negative <- prior#
    t.value$Posterior <-#
}#
#
sourceGrid <- function(fileDirectory, sourceDefinitions, time, source.hypotheses) {#
    setwd(fileDirectory)#
    temp <- list.files(pattern="*.txt")#
    myRWL <- pblapply(temp, readRWLArima)#
    myJackKnife <- lapply(myRWL,  function(x) treeJackKnifeMultipleSourceSig(time, x, source.list, return="t-value"))#
    mySigDef <- lapply(myJackKnife, function(x) populationSigDefinitionMultiple(x, source.hypotheses))#
    myResults <- ldply (mySigDef, data.frame)#
    rownames(myResults) <- gsub(".txt", "", temp, )#
    return(myResults)#
}#
################
###Load Data####
################
####Define Time#
time <- seq(1600, 1900, 1)#
#
all <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco/All Guitermann Data.csv")#
#
CHU <- data.frame(all$Year, auto.arima(all$CHU)$residuals)#
colnames(CHU) <- c("Year", "CHU")#
#
CEB <- data.frame(all$Year, auto.arima(all$CEB)$residuals)#
colnames(CEB) <- c("Year", "CEB")#
#
CIB <- data.frame(all$Year, auto.arima(all$CIB)$residuals)#
colnames(CIB) <- c("Year", "CIB")#
#
GOB <- data.frame(all$Year, auto.arima(all$GOB)$residuals)#
colnames(GOB) <- c("Year", "GOB")#
#
JEM <- data.frame(all$Year, auto.arima(all$JEM)$residuals)#
colnames(JEM) <- c("Year", "JEM")#
#
MEA <- data.frame(all$Year, auto.arima(all$MEA)$residuals)#
colnames(MEA) <- c("Year", "MEA")#
#
MVER <- data.frame(all$Year, auto.arima(all$MVER)$residuals)#
colnames(MVER) <- c("Year", "MVER")#
#
DUR <- data.frame(all$Year, auto.arima(all$DUR)$residuals)#
colnames(DUR) <- c("Year", "DUR")#
#
source.hypotheses <- c("CHU","CEB","CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.frame <- data.frame(CHU$Year, CHU$CHU, CEB$CEB, CIB$CIB, GOB$GOB, JEM$JEM, MEA$MEA, MVER$MVER, DUR$DUR)#
colnames(source.frame) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
all.sources <- data.frame(all$Year, all$CHU, all$CEB, all$CIB, all$GOB, all$JEM, all$MEA, all$MVER,  all$DUR)#
colnames(all.sources) <- c("Year", "CHU", "CEB", "CIB", "GOB", "JEM", "MEA", "MVER", "DUR")#
#
source.list <- list(CHU, CEB, CIB, GOB, JEM, MEA, MVER, DUR)
####Chuska Mountains#
results.chu <- data.frame(results$Long, results$Lat, results$CHU)#
colnames(results.chu) <- c("Long", "Lat", "CHU")#
#
results.int.chu <- with(results.chu, interp(x=Long, y=Lat, z=CHU, duplicate="mean", nx=300, ny=300))#
results.int.chu.melt <- reshape2::melt(results.int.chu$z, na.rm=TRUE)#
colnames(results.int.chu.melt) <- c("x", "y", "z")#
#
results.int.chu.melt$x <- results.int.chu$x[results.int.chu.melt$x]#
results.int.chu.melt$y <- results.int.chu$y[results.int.chu.melt$y]#
#
results.int.chu.melt[is.na(results.int.chu.melt)] <- 0#
#
ChuskaSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.chu.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
#stat_contour(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.chu.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CHU), colour="black", alpha=0.2, data=results.chu) +#
geom_text(aes(x=-108.8, y=35.6, label="Chuska#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Chuska Mountains") +#
guides(size=FALSE)#
ggsave(ChuskaSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Chuska.tiff", device="tiff", dpi=300, width=7, height=7)#
####Zuni Mountains#
results.cib <- data.frame(results$Long, results$Lat, results$CIB)#
colnames(results.cib) <- c("Long", "Lat", "CIB")#
#
results.int.cib <- with(results.cib, interp(x=Long, y=Lat, z=CIB, duplicate="mean", nx=300, ny=300))#
results.int.cib.melt <- melt(results.int.cib$z, na.rm=TRUE)#
colnames(results.int.cib.melt) <- c("x", "y", "z")#
#
results.int.cib.melt$x <- results.int.cib$x[results.int.cib.melt$x]#
results.int.cib.melt$y <- results.int.cib$y[results.int.cib.melt$y]#
#
results.int.cib.melt[is.na(results.int.cib.melt)] <- 0#
#
ZuniSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CIB), colour="black", alpha=0.2, data=results.cib) +#
geom_text(aes(x=-108.8, y=35.6, label="Zuni#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Zuni Mountains") +#
guides(size=FALSE)#
ggsave(ZuniSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Zuni.tiff", device="tiff", dpi=300, width=7, height=7)#
####Mesa Verde#
results.mver <- data.frame(results$Long, results$Lat, results$MVER)#
colnames(results.mver) <- c("Long", "Lat", "MVER")#
#
results.int.mver <- with(results.mver, interp(x=Long, y=Lat, z=MVER, duplicate="mean", nx=300, ny=300))#
results.int.mver.melt <- melt(results.int.mver$z, na.rm=TRUE)#
colnames(results.int.mver.melt) <- c("x", "y", "z")#
#
results.int.mver.melt$x <- results.int.mver$x[results.int.mver.melt$x]#
results.int.mver.melt$y <- results.int.mver$y[results.int.mver.melt$y]#
#
results.int.mver.melt[is.na(results.int.mver.melt)] <- 0#
#
MesaVerdeSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.mver.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.mver.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=MVER), colour="black", alpha=0.2, data=results.mver) +#
geom_text(aes(x=-108.5, y=37, label="Mesa Verde"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Mesa Verde") +#
guides(size=FALSE)#
ggsave(MesaVerdeSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/MesaVerde.tiff", device="tiff", dpi=300, width=7, height=7)#
####North Jemez#
results.mea <- data.frame(results$Long, results$Lat, results$MEA)#
colnames(results.mea) <- c("Long", "Lat", "MEA")#
#
results.int.mea <- with(results.mea, interp(x=Long, y=Lat, z=MEA, duplicate="mean", nx=300, ny=300))#
results.int.mea.melt <- melt(results.int.mea$z, na.rm=TRUE)#
colnames(results.int.mea.melt) <- c("x", "y", "z")#
#
results.int.mea.melt$x <- results.int.mea$x[results.int.mea.melt$x]#
results.int.mea.melt$y <- results.int.mea$y[results.int.mea.melt$y]#
#
results.int.mea.melt[is.na(results.int.mea.melt)] <- 0#
#
NorthJemezSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.mea.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.mea.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=MEA), colour="black", alpha=0.2, data=results.mea) +#
geom_text(aes(x=-106.55, y=36.95, label="North Jemez#
Mountains"))+geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("North Jemez Mountains") +#
guides(size=FALSE)#
ggsave(NorthJemezSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/NorthJemez.tiff", device="tiff", dpi=300, width=7, height=7)#
####South Jemez#
results.jem <- data.frame(results$Long, results$Lat, results$JEM)#
colnames(results.jem) <- c("Long", "Lat", "JEM")#
#
results.int.jem <- with(results.jem, interp(x=Long, y=Lat, z=JEM, duplicate="mean", nx=300, ny=300))#
results.int.jem.melt <- melt(results.int.jem$z, na.rm=TRUE)#
colnames(results.int.jem.melt) <- c("x", "y", "z")#
#
results.int.jem.melt$x <- results.int.jem$x[results.int.jem.melt$x]#
results.int.jem.melt$y <- results.int.jem$y[results.int.jem.melt$y]#
#
results.int.jem.melt[is.na(results.int.jem.melt)] <- 0#
#
SouthJemezSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.jem.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.jem.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=JEM), colour="black", alpha=0.2, data=results.jem) +#
geom_text(aes(x=-106.8, y=35.4, label="South#
Jemez#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("South Jemez Mountains") +#
guides(size=FALSE)#
ggsave(SouthJemezSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/SouthJemez.tiff", device="tiff", dpi=300, width=7, height=7)#
####Gobernador#
results.gob <- data.frame(results$Long, results$Lat, results$GOB)#
colnames(results.gob) <- c("Long", "Lat", "GOB")#
#
results.int.gob <- with(results.gob, interp(x=Long, y=Lat, z=GOB, duplicate="mean", nx=300, ny=300))#
results.int.gob.melt <- melt(results.int.gob$z, na.rm=TRUE)#
colnames(results.int.gob.melt) <- c("x", "y", "z")#
#
results.int.gob.melt$x <- results.int.gob$x[results.int.gob.melt$x]#
results.int.gob.melt$y <- results.int.gob$y[results.int.gob.melt$y]#
#
results.int.gob.melt[is.na(results.int.gob.melt)] <- 0#
#
GobSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.gob.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.gob.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=GOB), colour="black", alpha=0.2, data=results.gob) +#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Gobernador") +#
guides(size=FALSE)#
ggsave(GobSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Gobernador.tiff", device="tiff", dpi=300, width=7, height=7)#
####San Juan Mountains#
results.dur <- data.frame(results$Long, results$Lat, results$DUR)#
colnames(results.dur) <- c("Long", "Lat", "DUR")#
#
results.int.dur <- with(results.dur, interp(x=Long, y=Lat, z=DUR, duplicate="mean", nx=300, ny=300))#
results.int.dur.melt <- melt(results.int.dur$z, na.rm=TRUE)#
colnames(results.int.dur.melt) <- c("x", "y", "z")#
#
results.int.dur.melt$x <- results.int.dur$x[results.int.dur.melt$x]#
results.int.dur.melt$y <- results.int.dur$y[results.int.dur.melt$y]#
#
results.int.dur.melt[is.na(results.int.dur.melt)] <- 0#
#
SanJuanSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.dur.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.dur.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=DUR), colour="black", alpha=0.2, data=results.dur) +#
geom_text(aes(x=-106.2, y=37.8, label="San Juan#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("San Juan Mountains") +#
guides(size=FALSE)#
ggsave(SanJuanSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/SanJuan.tiff", device="tiff", dpi=300, width=7, height=7)#
####Mount Taylor#
results.ceb <- data.frame(results$Long, results$Lat, results$CEB)#
colnames(results.ceb) <- c("Long", "Lat", "CEB")#
#
results.int.ceb <- with(results.ceb, interp(x=Long, y=Lat, z=CEB, duplicate="mean", nx=300, ny=300))#
results.int.ceb.melt <- melt(results.int.ceb$z, na.rm=TRUE)#
colnames(results.int.ceb.melt) <- c("x", "y", "z")#
#
results.int.ceb.melt$x <- results.int.ceb$x[results.int.ceb.melt$x]#
results.int.ceb.melt$y <- results.int.ceb$y[results.int.ceb.melt$y]#
#
results.int.ceb.melt[is.na(results.int.ceb.melt)] <- 0#
#
MtTaylorSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.ceb.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.ceb.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CEB), colour="black", alpha=0.2, data=results.ceb) +#
geom_text(aes(x=-107.2, y=35.80, label="Mount#
Taylor"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Mount Taylor") +#
guides(size=FALSE)#
#
ggsave(MtTaylorSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/MtTaylor.tiff", device="tiff", dpi=300, width=7, height=7)#
####No Source#
results.none <- data.frame(results$Long, results$Lat, results$None)#
colnames(results.none) <- c("Long", "Lat", "None")#
#
results.int.none <- with(results.none, interp(x=Long, y=Lat, z=None, duplicate="mean", nx=300, ny=300))#
results.int.none.melt <- melt(results.int.none$z, na.rm=TRUE)#
colnames(results.int.none.melt) <- c("x", "y", "z")#
#
results.int.none.melt$x <- results.int.none$x[results.int.none.melt$x]#
results.int.none.melt$y <- results.int.none$y[results.int.none.melt$y]#
#
results.int.none.melt[is.na(results.int.none.melt)] <- 0#
#
NullSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.none.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.none.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=None), colour="black", alpha=0.2, data=results.none) +#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("No Definite Source") +#
guides(size=FALSE)#
#
ggsave(NullSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Null.tiff", device="tiff", dpi=300, width=7, height=7)
NM <- get_map(location=c(lon=-107.96, lat=36.06), zoom=7, maptype="terrain-background")#
results <- read.csv(file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/myResults.csv")
####Chuska Mountains#
results.chu <- data.frame(results$Long, results$Lat, results$CHU)#
colnames(results.chu) <- c("Long", "Lat", "CHU")#
#
results.int.chu <- with(results.chu, interp(x=Long, y=Lat, z=CHU, duplicate="mean", nx=300, ny=300))#
results.int.chu.melt <- reshape2::melt(results.int.chu$z, na.rm=TRUE)#
colnames(results.int.chu.melt) <- c("x", "y", "z")#
#
results.int.chu.melt$x <- results.int.chu$x[results.int.chu.melt$x]#
results.int.chu.melt$y <- results.int.chu$y[results.int.chu.melt$y]#
#
results.int.chu.melt[is.na(results.int.chu.melt)] <- 0#
#
ChuskaSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.chu.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
#stat_contour(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.chu.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CHU), colour="black", alpha=0.2, data=results.chu) +#
geom_text(aes(x=-108.8, y=35.6, label="Chuska#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Chuska Mountains") +#
guides(size=FALSE)#
ggsave(ChuskaSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Chuska.tiff", device="tiff", dpi=300, width=7, height=7)#
####Zuni Mountains#
results.cib <- data.frame(results$Long, results$Lat, results$CIB)#
colnames(results.cib) <- c("Long", "Lat", "CIB")#
#
results.int.cib <- with(results.cib, interp(x=Long, y=Lat, z=CIB, duplicate="mean", nx=300, ny=300))#
results.int.cib.melt <- melt(results.int.cib$z, na.rm=TRUE)#
colnames(results.int.cib.melt) <- c("x", "y", "z")#
#
results.int.cib.melt$x <- results.int.cib$x[results.int.cib.melt$x]#
results.int.cib.melt$y <- results.int.cib$y[results.int.cib.melt$y]#
#
results.int.cib.melt[is.na(results.int.cib.melt)] <- 0#
#
ZuniSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.cib.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CIB), colour="black", alpha=0.2, data=results.cib) +#
geom_text(aes(x=-108.8, y=35.6, label="Zuni#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Zuni Mountains") +#
guides(size=FALSE)#
ggsave(ZuniSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Zuni.tiff", device="tiff", dpi=300, width=7, height=7)#
####Mesa Verde#
results.mver <- data.frame(results$Long, results$Lat, results$MVER)#
colnames(results.mver) <- c("Long", "Lat", "MVER")#
#
results.int.mver <- with(results.mver, interp(x=Long, y=Lat, z=MVER, duplicate="mean", nx=300, ny=300))#
results.int.mver.melt <- melt(results.int.mver$z, na.rm=TRUE)#
colnames(results.int.mver.melt) <- c("x", "y", "z")#
#
results.int.mver.melt$x <- results.int.mver$x[results.int.mver.melt$x]#
results.int.mver.melt$y <- results.int.mver$y[results.int.mver.melt$y]#
#
results.int.mver.melt[is.na(results.int.mver.melt)] <- 0#
#
MesaVerdeSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.mver.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.mver.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=MVER), colour="black", alpha=0.2, data=results.mver) +#
geom_text(aes(x=-108.5, y=37, label="Mesa Verde"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Mesa Verde") +#
guides(size=FALSE)#
ggsave(MesaVerdeSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/MesaVerde.tiff", device="tiff", dpi=300, width=7, height=7)#
####North Jemez#
results.mea <- data.frame(results$Long, results$Lat, results$MEA)#
colnames(results.mea) <- c("Long", "Lat", "MEA")#
#
results.int.mea <- with(results.mea, interp(x=Long, y=Lat, z=MEA, duplicate="mean", nx=300, ny=300))#
results.int.mea.melt <- melt(results.int.mea$z, na.rm=TRUE)#
colnames(results.int.mea.melt) <- c("x", "y", "z")#
#
results.int.mea.melt$x <- results.int.mea$x[results.int.mea.melt$x]#
results.int.mea.melt$y <- results.int.mea$y[results.int.mea.melt$y]#
#
results.int.mea.melt[is.na(results.int.mea.melt)] <- 0#
#
NorthJemezSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.mea.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.mea.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=MEA), colour="black", alpha=0.2, data=results.mea) +#
geom_text(aes(x=-106.55, y=36.95, label="North Jemez#
Mountains"))+geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("North Jemez Mountains") +#
guides(size=FALSE)#
ggsave(NorthJemezSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/NorthJemez.tiff", device="tiff", dpi=300, width=7, height=7)#
####South Jemez#
results.jem <- data.frame(results$Long, results$Lat, results$JEM)#
colnames(results.jem) <- c("Long", "Lat", "JEM")#
#
results.int.jem <- with(results.jem, interp(x=Long, y=Lat, z=JEM, duplicate="mean", nx=300, ny=300))#
results.int.jem.melt <- melt(results.int.jem$z, na.rm=TRUE)#
colnames(results.int.jem.melt) <- c("x", "y", "z")#
#
results.int.jem.melt$x <- results.int.jem$x[results.int.jem.melt$x]#
results.int.jem.melt$y <- results.int.jem$y[results.int.jem.melt$y]#
#
results.int.jem.melt[is.na(results.int.jem.melt)] <- 0#
#
SouthJemezSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.jem.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.jem.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=JEM), colour="black", alpha=0.2, data=results.jem) +#
geom_text(aes(x=-106.8, y=35.4, label="South#
Jemez#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("South Jemez Mountains") +#
guides(size=FALSE)#
ggsave(SouthJemezSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/SouthJemez.tiff", device="tiff", dpi=300, width=7, height=7)#
####Gobernador#
results.gob <- data.frame(results$Long, results$Lat, results$GOB)#
colnames(results.gob) <- c("Long", "Lat", "GOB")#
#
results.int.gob <- with(results.gob, interp(x=Long, y=Lat, z=GOB, duplicate="mean", nx=300, ny=300))#
results.int.gob.melt <- melt(results.int.gob$z, na.rm=TRUE)#
colnames(results.int.gob.melt) <- c("x", "y", "z")#
#
results.int.gob.melt$x <- results.int.gob$x[results.int.gob.melt$x]#
results.int.gob.melt$y <- results.int.gob$y[results.int.gob.melt$y]#
#
results.int.gob.melt[is.na(results.int.gob.melt)] <- 0#
#
GobSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.gob.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.gob.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=GOB), colour="black", alpha=0.2, data=results.gob) +#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Gobernador") +#
guides(size=FALSE)#
ggsave(GobSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Gobernador.tiff", device="tiff", dpi=300, width=7, height=7)#
####San Juan Mountains#
results.dur <- data.frame(results$Long, results$Lat, results$DUR)#
colnames(results.dur) <- c("Long", "Lat", "DUR")#
#
results.int.dur <- with(results.dur, interp(x=Long, y=Lat, z=DUR, duplicate="mean", nx=300, ny=300))#
results.int.dur.melt <- melt(results.int.dur$z, na.rm=TRUE)#
colnames(results.int.dur.melt) <- c("x", "y", "z")#
#
results.int.dur.melt$x <- results.int.dur$x[results.int.dur.melt$x]#
results.int.dur.melt$y <- results.int.dur$y[results.int.dur.melt$y]#
#
results.int.dur.melt[is.na(results.int.dur.melt)] <- 0#
#
SanJuanSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.dur.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.dur.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=DUR), colour="black", alpha=0.2, data=results.dur) +#
geom_text(aes(x=-106.2, y=37.8, label="San Juan#
Mountains"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("San Juan Mountains") +#
guides(size=FALSE)#
ggsave(SanJuanSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/SanJuan.tiff", device="tiff", dpi=300, width=7, height=7)#
####Mount Taylor#
results.ceb <- data.frame(results$Long, results$Lat, results$CEB)#
colnames(results.ceb) <- c("Long", "Lat", "CEB")#
#
results.int.ceb <- with(results.ceb, interp(x=Long, y=Lat, z=CEB, duplicate="mean", nx=300, ny=300))#
results.int.ceb.melt <- melt(results.int.ceb$z, na.rm=TRUE)#
colnames(results.int.ceb.melt) <- c("x", "y", "z")#
#
results.int.ceb.melt$x <- results.int.ceb$x[results.int.ceb.melt$x]#
results.int.ceb.melt$y <- results.int.ceb$y[results.int.ceb.melt$y]#
#
results.int.ceb.melt[is.na(results.int.ceb.melt)] <- 0#
#
MtTaylorSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.ceb.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.ceb.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=CEB), colour="black", alpha=0.2, data=results.ceb) +#
geom_text(aes(x=-107.2, y=35.80, label="Mount#
Taylor"))+#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("Mount Taylor") +#
guides(size=FALSE)#
#
ggsave(MtTaylorSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/MtTaylor.tiff", device="tiff", dpi=300, width=7, height=7)#
####No Source#
results.none <- data.frame(results$Long, results$Lat, results$None)#
colnames(results.none) <- c("Long", "Lat", "None")#
#
results.int.none <- with(results.none, interp(x=Long, y=Lat, z=None, duplicate="mean", nx=300, ny=300))#
results.int.none.melt <- melt(results.int.none$z, na.rm=TRUE)#
colnames(results.int.none.melt) <- c("x", "y", "z")#
#
results.int.none.melt$x <- results.int.none$x[results.int.none.melt$x]#
results.int.none.melt$y <- results.int.none$y[results.int.none.melt$y]#
#
results.int.none.melt[is.na(results.int.none.melt)] <- 0#
#
NullSigPlot <- ggmap(NM, alpha=0.2) +#
#stat_contour(data=results.int.none.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_tile(data=results.int.none.melt, aes(x=x, y=y, z=z, fill=z, alpha=z))+#
geom_point(aes(Long, Lat, size=None), colour="black", alpha=0.2, data=results.none) +#
geom_text(aes(x=-108.08, y=36.25, label="Chaco Canyon"))+#
geom_point(aes(x=-108.05, y=36.1), shape=17, size=5) +#
coord_equal() +#
scale_fill_gradient(name = "Source Correlation", low="white", high="red", na.value="white", labels = scales::percent, limits = c(0, 1)) +#
scale_alpha(guide="none") +#
scale_y_continuous("Latitude", limits = c(35, 38)) +#
scale_x_continuous("Longitude", limits = c(-110, -106)) +#
coord_map() +#
theme_light() +#
ggtitle("No Definite Source") +#
guides(size=FALSE)#
#
ggsave(NullSigPlot, file="/Users/lee/Dropbox/Documents/Chaco/Tree Rings/Results/Null.tiff", device="tiff", dpi=300, width=7, height=7)
library(devtools)
devtools::install_github("paleolimbot/ggspatial")
install_github("paleolimbot/ggspatial")
library(shiny)
runApp("~/GitHub/CloudCal")
